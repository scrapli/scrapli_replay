{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"scrapli replay","text":"<p>Scrapli replay is a set of tools to help you easily test scrapli programs. Scrapli replay contains a pytest plugin  which can \"wrap\" your tests that contain scrapli interactions and record and play them back -- this allows you to  store \"cached\" test sessions. These cached test sessions can be stored in version control and give you the ability  to ensure scrapli is behaving as it should even without devices available (such as in your CI setup).</p> <p>scrapli replay also contains a \"collector\" and a \"server\" which allow you to \"collect\" interactions from live  devices, and then build mock ssh server(s) that look and feel pretty close to the real deal! Check out the docs for  more info!</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#20220130","title":"2022.01.30","text":"<ul> <li>Dropped Python3.6 support as it is now EOL! Of course, scrapli probably still works just fine with 3.6 (if you    install the old 3.6 requirements), but we won't test/support it anymore.</li> <li>Some typing cleanup based on updated asyncssh typing additions.</li> <li>Fixed poorly used private attribute (on my end) causing scrapli-replay to break with asyncssh 2.9 strictly due to    a typing issue.</li> </ul>"},{"location":"changelog/#20210228","title":"2021.02.28","text":"<ul> <li>Initial release</li> </ul>"},{"location":"about/code_of_conduct/","title":"Code of Conduct","text":"<p>Be excellent to each other!</p>"},{"location":"about/contributing/","title":"Contributing","text":"<p>Thanks for thinking about contributing! Contributions are not expected, but are quite welcome.</p> <p>Contributions of all kinds are welcomed -- typos, doc updates, adding examples, bug fixes, and feature adds.</p> <p>Some notes on contributing:</p> <ul> <li>Please open a GitHub discussion topic for any potential feature adds/changes to discuss them prior to opening a PR,   this way everyone has a chance to chime in and make sure we're all on the same page!</li> <li>Please open an issue to discuss any bugs/bug fixes prior to opening a PR.</li> <li>Once we all have discussed any adds/changes, pull requests are very much welcome and appreciated!</li> <li>All PRs should pass tests/CI linting -- checkout the Makefile for some shortcuts for linting and testing.</li> <li>Please include tests! Even simple/basic tests are better than nothing -- it helps make sure changes in the future    don't break functionality or make things act in unexpected ways!</li> </ul>"},{"location":"more_scrapli/nornir_scrapli/","title":"Nornir scrapli","text":"<p>If you want to use scrapli, but don't want to deal with handling concurrency yourself, there is great news! The  nornir_scrapli plugin allows you to use scrapli (and scrapli netconf  and scrapli cfg) within the Nornir framework!</p>"},{"location":"more_scrapli/scrapli/","title":"Scrapli","text":"<p>scrapli (docs) is the  \"parent\" scrapli library. Check it out if you need to connect to devices with telnet or ssh!</p>"},{"location":"more_scrapli/scrapli_cfg/","title":"Scrapli Cfg","text":"<p>scrapli_cfg (docs)  is utility that accepts a scrapli Telnet or SSH connection and provides configuration management capabilities.  scrapli_cfg allows you to load candidate configurations for merge or replace operations, generate diffs of the  current vs candidate, and of course commit or abort the candidate configuration.</p>"},{"location":"more_scrapli/scrapli_community/","title":"Scrapli Community","text":"<p>If you would like to use scrapli, but the platform(s) that you work with are not supported in the \"core\" scrapli  platforms, you should check out scrapli_community! This is the place  for users to share \"non-core\" scrapli platforms.</p>"},{"location":"more_scrapli/scrapli_netconf/","title":"Scrapli Netconf","text":"<p>scrapli_netconf (docs)  is a netconf driver built on top of scrapli. The purpose of scrapli_netconf is to provide a fast, flexible,  thoroughly tested, well typed, well documented, simple API that supports both synchronous and asynchronous usage.  Working together scrapli and scrapli_netconf aim to provide a consistent (as is practical) look and feel when  automating devices over telnet, SSH, or netconf (over SSH).</p>"},{"location":"more_scrapli/scrapli_scp/","title":"Scrapli SCP","text":"<p>scrapli_scp is all about adding smart SCP capability to scrapli --  specifically with asyncssh. If you need to SCP things and are using scrapli, you should check this awesome addition  to the scrapli community. Big thanks to Viktor for building this and sharing it  with the community!</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>exceptions</li> <li>logging</li> <li>replay<ul> <li>pytest_scrapli_replay</li> <li>replay</li> </ul> </li> <li>server<ul> <li>collector</li> <li>server</li> </ul> </li> </ul>"},{"location":"reference/exceptions/","title":"Exceptions","text":"<p>scrapli_replay.exceptions</p>"},{"location":"reference/exceptions/#exceptions.ScrapliReplayConnectionProfileError","title":"<code>ScrapliReplayConnectionProfileError</code>","text":"<p>         Bases: <code>ScrapliReplayException</code></p> <p>Exception for connection profile errors</p> Source code in <code>scrapli_replay/exceptions.py</code> <pre><code>class ScrapliReplayConnectionProfileError(ScrapliReplayException):\n\"\"\"Exception for connection profile errors\"\"\"\n</code></pre>"},{"location":"reference/exceptions/#exceptions.ScrapliReplayException","title":"<code>ScrapliReplayException</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Base class for scrapli_replay exceptions</p> <p>Does not inherit from scrapli base exception so that these exceptions are very clearly not from \"normal\" scrapli!</p> Source code in <code>scrapli_replay/exceptions.py</code> <pre><code>class ScrapliReplayException(Exception):\n\"\"\"\n    Base class for scrapli_replay exceptions\n\n    Does not inherit from scrapli base exception so that these exceptions are very clearly not from\n    \"normal\" scrapli!\n\n    \"\"\"\n</code></pre>"},{"location":"reference/exceptions/#exceptions.ScrapliReplayExpectedInputError","title":"<code>ScrapliReplayExpectedInputError</code>","text":"<p>         Bases: <code>ScrapliReplayException</code></p> <p>Exception for errors where expected inputs do not match reality</p> Source code in <code>scrapli_replay/exceptions.py</code> <pre><code>class ScrapliReplayExpectedInputError(ScrapliReplayException):\n\"\"\"Exception for errors where expected inputs do not match reality\"\"\"\n</code></pre>"},{"location":"reference/exceptions/#exceptions.ScrapliReplayServerError","title":"<code>ScrapliReplayServerError</code>","text":"<p>         Bases: <code>ScrapliReplayException</code></p> <p>Base exception for scrapli_replay server related errors</p> Source code in <code>scrapli_replay/exceptions.py</code> <pre><code>class ScrapliReplayServerError(ScrapliReplayException):\n\"\"\"Base exception for scrapli_replay server related errors\"\"\"\n</code></pre>"},{"location":"reference/logging/","title":"Logging","text":"<p>scrapli_replay.logging</p>"},{"location":"reference/logging/#logging.ScrapliReplayFormatter","title":"<code>ScrapliReplayFormatter</code>","text":"<p>         Bases: <code>Formatter_</code></p> Source code in <code>scrapli_replay/logging.py</code> <pre><code>class ScrapliReplayFormatter(Formatter_):\n    def __init__(self, log_header: bool = True, caller_info: bool = False) -&gt; None:\n\"\"\"\n        Scrapli Replay Formatter\n\n        Emit nicely formatted log messages\n\n        Args:\n            log_header: print log header or not\n            caller_info: print caller info or not (like module/function/lineno)\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        log_format = \"{message_id:&lt;5} | {asctime} | {levelname:&lt;8} | {message}\"\n        if caller_info:\n            log_format = (\n                \"{message_id:&lt;5} | {asctime} | {levelname:&lt;8} | \"\n                \"{module:&lt;20} | {funcName:&lt;20} | {lineno:&lt;5} | {message}\"\n            )\n\n        super().__init__(fmt=log_format, style=\"{\")\n\n        self.log_header = log_header\n        self.caller_info = caller_info\n        self.message_id = 1\n\n        self.header_record = LogRecord_(\n            name=\"header\",\n            level=0,\n            pathname=\"\",\n            lineno=0,\n            msg=\"MESSAGE\",\n            args=(),\n            exc_info=None,\n        )\n        self.header_record.message_id = 0\n        self.header_record.asctime = \"TIMESTAMP\".ljust(23, \" \")\n        self.header_record.levelname = \"LEVEL\"\n        self.header_record.module = \"MODULE\"\n        self.header_record.funcName = \"FUNCNAME\"\n        self.header_record.lineno = 0\n        self.header_record.message = \"MESSAGE\"\n\n    def formatMessage(self, record: LogRecord_) -&gt; str:\n\"\"\"\n        Override standard library logging Formatter.formatMessage\n\n        Args:\n            record: LogRecord to format\n\n        Returns:\n            str: log string to emit\n\n        Raises:\n            N/A\n\n        \"\"\"\n        record.message_id = self.message_id\n\n        if self.caller_info:\n            record.module = (\n                record.module[:20] if len(record.module) &lt;= 20 else f\"{record.module[:17]}...\"\n            )\n            record.funcName = (\n                record.funcName[:20] if len(record.funcName) &lt;= 20 else f\"{record.funcName[:17]}...\"\n            )\n\n        message = self._style.format(record)\n\n        if self.message_id == 1 and self.log_header:\n            # ignoring type for these fields so we can put \"pretty\" data into the log \"header\" row\n            self.header_record.message_id = \"ID\"\n            self.header_record.lineno = \"LINE\"  # type: ignore\n            header_message = self._style.format(self.header_record)\n            message = header_message + \"\\n\" + message\n\n        self.message_id += 1\n\n        return message\n</code></pre>"},{"location":"reference/logging/#logging.ScrapliReplayFormatter.__init__","title":"<code>__init__(log_header: bool = True, caller_info: bool = False) -&gt; None</code>","text":"<p>Scrapli Replay Formatter</p> <p>Emit nicely formatted log messages</p> <p>Parameters:</p> Name Type Description Default <code>log_header</code> <code>bool</code> <p>print log header or not</p> <code>True</code> <code>caller_info</code> <code>bool</code> <p>print caller info or not (like module/function/lineno)</p> <code>False</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>scrapli_replay/logging.py</code> <pre><code>def __init__(self, log_header: bool = True, caller_info: bool = False) -&gt; None:\n\"\"\"\n    Scrapli Replay Formatter\n\n    Emit nicely formatted log messages\n\n    Args:\n        log_header: print log header or not\n        caller_info: print caller info or not (like module/function/lineno)\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    log_format = \"{message_id:&lt;5} | {asctime} | {levelname:&lt;8} | {message}\"\n    if caller_info:\n        log_format = (\n            \"{message_id:&lt;5} | {asctime} | {levelname:&lt;8} | \"\n            \"{module:&lt;20} | {funcName:&lt;20} | {lineno:&lt;5} | {message}\"\n        )\n\n    super().__init__(fmt=log_format, style=\"{\")\n\n    self.log_header = log_header\n    self.caller_info = caller_info\n    self.message_id = 1\n\n    self.header_record = LogRecord_(\n        name=\"header\",\n        level=0,\n        pathname=\"\",\n        lineno=0,\n        msg=\"MESSAGE\",\n        args=(),\n        exc_info=None,\n    )\n    self.header_record.message_id = 0\n    self.header_record.asctime = \"TIMESTAMP\".ljust(23, \" \")\n    self.header_record.levelname = \"LEVEL\"\n    self.header_record.module = \"MODULE\"\n    self.header_record.funcName = \"FUNCNAME\"\n    self.header_record.lineno = 0\n    self.header_record.message = \"MESSAGE\"\n</code></pre>"},{"location":"reference/logging/#logging.ScrapliReplayFormatter.formatMessage","title":"<code>formatMessage(record: LogRecord_) -&gt; str</code>","text":"<p>Override standard library logging Formatter.formatMessage</p> <p>Parameters:</p> Name Type Description Default <code>record</code> <code>LogRecord_</code> <p>LogRecord to format</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>log string to emit</p> Source code in <code>scrapli_replay/logging.py</code> <pre><code>def formatMessage(self, record: LogRecord_) -&gt; str:\n\"\"\"\n    Override standard library logging Formatter.formatMessage\n\n    Args:\n        record: LogRecord to format\n\n    Returns:\n        str: log string to emit\n\n    Raises:\n        N/A\n\n    \"\"\"\n    record.message_id = self.message_id\n\n    if self.caller_info:\n        record.module = (\n            record.module[:20] if len(record.module) &lt;= 20 else f\"{record.module[:17]}...\"\n        )\n        record.funcName = (\n            record.funcName[:20] if len(record.funcName) &lt;= 20 else f\"{record.funcName[:17]}...\"\n        )\n\n    message = self._style.format(record)\n\n    if self.message_id == 1 and self.log_header:\n        # ignoring type for these fields so we can put \"pretty\" data into the log \"header\" row\n        self.header_record.message_id = \"ID\"\n        self.header_record.lineno = \"LINE\"  # type: ignore\n        header_message = self._style.format(self.header_record)\n        message = header_message + \"\\n\" + message\n\n    self.message_id += 1\n\n    return message\n</code></pre>"},{"location":"reference/replay/","title":"Index","text":""},{"location":"reference/replay/pytest_scrapli_replay/","title":"Pytest scrapli replay","text":"<p>scrapli_replay.pytest.scrapli_replay</p>"},{"location":"reference/replay/pytest_scrapli_replay/#replay.pytest_scrapli_replay.async_scrapli_replay","title":"<code>async_scrapli_replay(request: SubRequest) -&gt; AsyncIterator[None]</code>  <code>async</code>","text":"<p>Async version of Scrapli replay pytest plugin</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>SubRequest</code> <p>pytest request object</p> required <p>Yields:</p> Type Description <code>AsyncIterator[None]</code> <p>None</p> Source code in <code>replay/pytest_scrapli_replay.py</code> <pre><code>@pytest.mark.asyncio\n@pytest.fixture(scope=\"function\")\nasync def async_scrapli_replay(request: SubRequest) -&gt; AsyncIterator[None]:\n\"\"\"\n    Async version of Scrapli replay pytest plugin\n\n    Args:\n        request: pytest request object\n\n    Yields:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    # importing here to not break coverage for the rest of things... if/when this import is not here\n    # it gets imported *before* coverage starts which means that the things in replay.replay dont\n    # get proper coverage figured out\n    from scrapli_replay.replay.replay import ScrapliReplay  # pylint: disable=C0415\n\n    (\n        opt_replay_mode,\n        session_directory,\n        opt_overwrite,\n        opt_disable,\n        test_name,\n        opt_block_network,\n    ) = _finalize_fixture_args(request=request)\n\n    if test_name in opt_overwrite:\n        opt_replay_mode = \"overwrite\"\n\n    if not opt_disable:\n        async with ScrapliReplay(\n            session_directory=session_directory,\n            session_name=test_name,\n            replay_mode=opt_replay_mode,\n            block_network=opt_block_network,\n        ):\n            yield\n    else:\n        yield\n</code></pre>"},{"location":"reference/replay/pytest_scrapli_replay/#replay.pytest_scrapli_replay.pytest_addoption","title":"<code>pytest_addoption(parser: Parser) -&gt; None</code>","text":"<p>Scrapli Replay Pytest options</p> <p>Parameters:</p> Name Type Description Default <code>parser</code> <code>Parser</code> <p>pytest option Parser</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>replay/pytest_scrapli_replay.py</code> <pre><code>def pytest_addoption(parser: Parser) -&gt; None:\n\"\"\"\n    Scrapli Replay Pytest options\n\n    Args:\n        parser: pytest option Parser\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    group = parser.getgroup(\"scrapli_replay\")\n    group.addoption(\n        \"--scrapli-replay-mode\",\n        action=\"store\",\n        dest=\"scrapli_replay_mode\",\n        default=\"replay\",\n        choices=[\"replay\", \"record\", \"overwrite\"],\n        help=\"Set the recording mode for scrapli_replay\",\n    )\n    group.addoption(\n        \"--scrapli-replay-directory\",\n        action=\"store\",\n        dest=\"scrapli_replay_directory\",\n        default=None,\n        help=(\n            \"Set the recording output directory for scrapli_replay; if not set sessions are stored \"\n            \"in a 'scrapli_replay' folder in the directory of the test file\"\n        ),\n    )\n    group.addoption(\n        \"--scrapli-replay-overwrite\",\n        action=\"store\",\n        dest=\"scrapli_replay_overwrite\",\n        default=\"\",\n        help=(\n            \"Comma separated list of test names, these sessions will be overwritten (re-recorded)\"\n        ),\n    )\n    group.addoption(\n        \"--scrapli-replay-disable\",\n        action=\"store_true\",\n        dest=\"scrapli_replay_disable\",\n        default=False,\n        help=\"Disable scrapli_replay entirely\",\n    )\n    group.addoption(\n        \"--scrapli-replay-block-network\",\n        action=\"store_true\",\n        dest=\"scrapli_replay_block_network\",\n        default=False,\n        help=(\n            \"Disable scrapli_replay network connections -- tests will work *if* sessions are \"\n            \"already saved, no new sessions will be created/no connections will be made!\"\n        ),\n    )\n</code></pre>"},{"location":"reference/replay/pytest_scrapli_replay/#replay.pytest_scrapli_replay.pytest_load_initial_conftests","title":"<code>pytest_load_initial_conftests(early_config: Config, parser: Parser, args: Any) -&gt; None</code>","text":"<p>Register custom scrapli replay marker so scrapli replay can be used with pytest.mark</p> <p>This is not necessary if you just want to use scrapli_replay as a fixture, but it seems nicer to use it as a decorator (like pytest vcr). Also w/out this we get warnings and we dont want any of that silliness!</p> <p>Parameters:</p> Name Type Description Default <code>early_config</code> <code>Config</code> <p>pytest Config object</p> required <code>parser</code> <code>Parser</code> <p>pytest option Parser</p> required <code>args</code> <code>Any</code> <p>args... from something? I dunno</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>replay/pytest_scrapli_replay.py</code> <pre><code>def pytest_load_initial_conftests(early_config: Config, parser: Parser, args: Any) -&gt; None:\n\"\"\"\n    Register custom scrapli replay marker so scrapli replay can be used with pytest.mark\n\n    This is not necessary if you just want to use scrapli_replay as a fixture, but it seems nicer\n    to use it as a decorator (like pytest vcr). Also w/out this we get warnings and we dont want any\n    of that silliness!\n\n    Args:\n        early_config: pytest Config object\n        parser: pytest option Parser\n        args: args... from something? I dunno\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    # parser and args aren't necessary for us here\n    _, _ = parser, args\n    early_config.addinivalue_line(\n        \"markers\", \"scrapli_replay: Mark the test as using scrapli_replay\"\n    )\n</code></pre>"},{"location":"reference/replay/pytest_scrapli_replay/#replay.pytest_scrapli_replay.scrapli_replay","title":"<code>scrapli_replay(request: SubRequest) -&gt; Iterator[None]</code>","text":"<p>Scrapli replay pytest plugin</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>SubRequest</code> <p>pytest request object</p> required <p>Yields:</p> Type Description <code>Iterator[None]</code> <p>None</p> Source code in <code>replay/pytest_scrapli_replay.py</code> <pre><code>@pytest.fixture(scope=\"function\")\ndef scrapli_replay(request: SubRequest) -&gt; Iterator[None]:\n\"\"\"\n    Scrapli replay pytest plugin\n\n    Args:\n        request: pytest request object\n\n    Yields:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    # importing here to not break coverage for the rest of things... if/when this import is not here\n    # it gets imported *before* coverage starts which means that the things in replay.replay dont\n    # get proper coverage figured out\n    from scrapli_replay.replay.replay import ScrapliReplay  # pylint: disable=C0415\n\n    (\n        opt_replay_mode,\n        session_directory,\n        opt_overwrite,\n        opt_disable,\n        test_name,\n        opt_block_network,\n    ) = _finalize_fixture_args(request=request)\n\n    if test_name in opt_overwrite:\n        opt_replay_mode = \"overwrite\"\n\n    if not opt_disable:\n        with ScrapliReplay(\n            session_directory=session_directory,\n            session_name=test_name,\n            replay_mode=opt_replay_mode,\n            block_network=opt_block_network,\n        ):\n            yield\n    else:\n        yield\n</code></pre>"},{"location":"reference/replay/replay/","title":"Replay","text":"<p>scrapli_replay.replay.replay</p>"},{"location":"reference/replay/replay/#replay.replay.ScrapliReplay","title":"<code>ScrapliReplay</code>","text":"Source code in <code>replay/replay.py</code> <pre><code>class ScrapliReplay:\n    def __init__(\n        self,\n        *,\n        session_directory: Optional[str] = None,\n        session_name: Optional[str] = None,\n        replay_mode: str = \"record\",\n        block_network: bool = False,\n    ) -&gt; None:\n\"\"\"\n        Scrapli replay\n\n        Args:\n            session_directory: directory to write session data to\n            session_name: name of session to write out\n            replay_mode: replay mode to use\n            block_network: if set to True, no network connections will be made, though any stored\n                sessions will be ran normally\n\n        Returns:\n            None\n\n        Raises:\n            ScrapliReplayException: if invalid replay mode provided\n\n        \"\"\"\n        if session_directory is None or not Path(session_directory).is_dir():\n            self.session_directory = Path.cwd()\n        else:\n            self.session_directory = Path(session_directory)\n\n        # session name will generally come from pytest test name, but for ad-hoc use it can be\n        # auto-generated w/ timestamp\n        self.session_name = (\n            session_name or f\"scrapli_replay_session_{round(datetime.now().timestamp())}\"\n        )\n\n        if replay_mode not in (\n            \"record\",\n            \"replay\",\n            \"overwrite\",\n        ):\n            raise ScrapliReplayException(\"replay mode invalid\")\n\n        if replay_mode == \"record\" and self._session_exists():\n            print(\n                \"session exists but replay mode is not set to overwrite, using replay mode 'replay'\"\n            )\n            replay_mode = \"replay\"\n        elif not self._session_exists():\n            replay_mode = \"record\"\n\n        self.replay_mode = ReplayMode[replay_mode.upper()]\n\n        self.replay_session: Dict[str, Any] = {}\n        if self.replay_mode == ReplayMode.REPLAY:\n            with open(\n                f\"{self.session_directory}/{self.session_name}.yaml\", \"r\", encoding=\"utf-8\"\n            ) as f:\n                self.replay_session = YAML.load(f)\n            # if we open a session and there are no interactions recorded for any of the hosts then\n            # something is not right -- we will need to re-record a session\n            if not all(\n                instance_session.get(\"interactions\", None)\n                for instance_session in self.replay_session.values()\n            ):\n                self.replay_mode = ReplayMode.RECORD\n\n        self._block_network = block_network\n        self._patched_open: Optional[mock._patch[Any]] = None  # noqa\n        self.wrapped_instances: Dict[str, ScrapliReplayInstance] = {}\n\n        self._channel_close: Optional[Callable[[], None]] = None\n\n    def __call__(self, wrapped_func: Callable[..., Any]) -&gt; Callable[..., Any]:\n\"\"\"\n        Use ScrapliReplay as a decorator\n\n        Decide if the wrapped function is sync or async and wrap that function/coroutine in context\n        manager of self\n\n        Args:\n            wrapped_func: function being decorated\n\n        Returns:\n            decorate: decorated func\n\n        Raises:\n            N/A\n\n        \"\"\"\n        if asyncio.iscoroutinefunction(wrapped_func):\n\n            async def decorate(*args: Any, **kwargs: Any) -&gt; Any:\n                async with self:\n                    return await wrapped_func(*args, **kwargs)\n\n        else:\n            # ignoring type error:\n            # \"All conditional function variants must have identical signatures\"\n            # one is sync one is async so never going to be identical here!\n            def decorate(*args: Any, **kwargs: Any) -&gt; Any:  # type: ignore\n                with self:\n                    return wrapped_func(*args, **kwargs)\n\n        return decorate\n\n    def __enter__(self) -&gt; None:\n\"\"\"\n        Enter method for context manager\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n\n        def patched_open(cls: Driver) -&gt; None:\n\"\"\"\n            Patched Driver.open method\n\n            Patched at the driver and dealing w/ the on open/auth things as this way we never have\n            to think about which transport is being used\n\n            Args:\n                cls: scrapli Drive self\n\n            Returns:\n                None\n\n            Raises:\n                N/A\n\n            \"\"\"\n            instance_name = self.create_instance_name(scrapli_conn=cls)\n\n            cls.channel.open()\n            self._channel_close = cls.channel.close\n\n            connection_profile = self.create_connection_profile(scrapli_conn=cls)\n            instance_object = ScrapliReplayInstance(\n                replay_mode=self.replay_mode,\n                connection_profile=connection_profile,\n                replay_session=self.replay_session.get(instance_name, {}),\n            )\n            self.wrapped_instances[instance_name] = instance_object\n\n            if self.replay_mode == ReplayMode.REPLAY:\n                instance_object.setup_replay_mode(scrapli_conn=cls)\n            else:\n                if self._block_network is True:\n                    # if block network is true and we got here then there is no session recorded, so\n                    # we need to skip this test\n                    pytest.skip(\n                        \"scrapli-replay block-network is True, no session recorded, \"\n                        \"skipping test...\"\n                    )\n\n                # if we are not in replay mode, we are in record or overwrite (same/same) so setup\n                # the record read/write channel methods and then do \"normal\" stuff\n                instance_object.setup_record_mode(scrapli_conn=cls)\n                cls.transport.open()\n\n            cls._pre_open_closing_log(closing=False)  # pylint: disable=W0212\n\n            if cls.transport_name in (\"system\",) and not cls.auth_bypass:\n                cls.channel.channel_authenticate_ssh(\n                    auth_password=cls.auth_password,\n                    auth_private_key_passphrase=cls.auth_private_key_passphrase,\n                )\n            if (\n                cls.transport_name\n                in (\n                    \"telnet\",\n                    \"asynctelnet\",\n                )\n                and not cls.auth_bypass\n            ):\n                cls.channel.channel_authenticate_telnet(\n                    auth_username=cls.auth_username, auth_password=cls.auth_password\n                )\n                if self.replay_mode == ReplayMode.RECORD:\n                    instance_object.telnet_patch_update_log(auth_username=cls.auth_username)\n\n            if cls.on_open:\n                cls.on_open(cls)\n\n            cls._post_open_closing_log(closing=False)  # pylint: disable=W0212\n\n        self._patched_open = mock.patch.object(\n            target=scrapli.driver.base.sync_driver.Driver, attribute=\"open\", new=patched_open\n        )\n        self._patched_open.start()\n\n    def __exit__(\n        self,\n        exception_type: Optional[Type[BaseException]],\n        exception_value: Optional[BaseException],\n        traceback: Optional[TracebackType],\n    ) -&gt; None:\n\"\"\"\n        Exit method to cleanup for context manager\n\n        Args:\n            exception_type: exception type being raised\n            exception_value: message from exception being raised\n            traceback: traceback from exception being raised\n\n        Returns:\n            None\n\n        Raises:\n            ScrapliReplayException: if patched open is none for some reason\n\n        \"\"\"\n        if not self._patched_open:\n            raise ScrapliReplayException(\n                \"patched open is None, but we are in exit... this should never happen, definitely \"\n                \"a bug\"\n            )\n\n        self._patched_open.stop()\n\n        if self.replay_mode in (ReplayMode.RECORD, ReplayMode.OVERWRITE):\n            self._save()\n\n        if self._channel_close:\n            self._channel_close()\n\n    async def __aenter__(self) -&gt; None:\n\"\"\"\n        Enter method for context manager\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n\n        async def patched_open(cls: AsyncDriver) -&gt; None:\n\"\"\"\n            Patched AsyncDriver.open method\n\n            Patched at the driver and dealing w/ the on open/auth things as this way we never have\n            to think about which transport is being used\n\n            Args:\n                cls: scrapli Drive self\n\n            Returns:\n                None\n\n            Raises:\n                N/A\n\n            \"\"\"\n            instance_name = self.create_instance_name(scrapli_conn=cls)\n\n            cls.channel.open()\n            self._channel_close = cls.channel.close\n\n            connection_profile = self.create_connection_profile(scrapli_conn=cls)\n            instance_object = ScrapliReplayInstance(\n                replay_mode=self.replay_mode,\n                connection_profile=connection_profile,\n                replay_session=self.replay_session.get(instance_name, {}),\n            )\n            self.wrapped_instances[instance_name] = instance_object\n\n            if self.replay_mode == ReplayMode.REPLAY:\n                instance_object.setup_async_replay_mode(scrapli_conn=cls)\n            else:\n                if self._block_network is True:\n                    # if block network is true and we got here then there is no session recorded, so\n                    # we need to skip this test\n                    pytest.skip(\n                        \"scrapli-replay block-network is True, no session recorded, \"\n                        \"skipping test...\"\n                    )\n\n                # if we are not in replay mode, we are in record or overwrite (same/same) so setup\n                # the record read/write channel methods and then do \"normal\" stuff\n                instance_object.setup_async_record_mode(scrapli_conn=cls)\n                await cls.transport.open()\n\n            cls._pre_open_closing_log(closing=False)  # pylint: disable=W0212\n\n            if (\n                cls.transport_name\n                in (\n                    \"telnet\",\n                    \"asynctelnet\",\n                )\n                and not cls.auth_bypass\n            ):\n                await cls.channel.channel_authenticate_telnet(\n                    auth_username=cls.auth_username, auth_password=cls.auth_password\n                )\n                if self.replay_mode == ReplayMode.RECORD:\n                    instance_object.telnet_patch_update_log(auth_username=cls.auth_username)\n\n            if cls.on_open:\n                await cls.on_open(cls)\n\n            cls._post_open_closing_log(closing=False)  # pylint: disable=W0212\n\n        self._patched_open = mock.patch.object(\n            scrapli.driver.base.async_driver.AsyncDriver, \"open\", new=patched_open\n        )\n        self._patched_open.start()\n\n    async def __aexit__(\n        self,\n        exception_type: Optional[Type[BaseException]],\n        exception_value: Optional[BaseException],\n        traceback: Optional[TracebackType],\n    ) -&gt; None:\n\"\"\"\n        Exit method to cleanup for async context manager\n\n        Args:\n            exception_type: exception type being raised\n            exception_value: message from exception being raised\n            traceback: traceback from exception being raised\n\n        Returns:\n            None\n\n        Raises:\n            ScrapliReplayException: if patched open is none for some reason\n\n        \"\"\"\n        if not self._patched_open:\n            raise ScrapliReplayException(\n                \"patched open is None, but we are in exit... this should never happen, definitely \"\n                \"a bug\"\n            )\n\n        self._patched_open.stop()\n\n        if self.replay_mode in (ReplayMode.RECORD, ReplayMode.OVERWRITE):\n            self._save()\n\n        if self._channel_close:\n            self._channel_close()\n\n    def create_instance_name(self, scrapli_conn: Union[AsyncDriver, Driver]) -&gt; str:\n\"\"\"\n        Create as unique as possible instance name for a given connection\n\n        Since hash cant be relied on to between python executions we need to have some way to have a\n        decent idea about what connection is what... using the host and port is maybe not enough as\n        a user may have multiple connections to the same device in a test session. Adding in the\n        transport *might* help (maybe one is ssh one is netconf or telnet), but still not 100%...\n        Adding in the logging uid is handy, but only if the user set one, so we also will tack on\n        an extra field basically counting how many of the same connections we've seen. We *may* not\n        support multiple connections because it may be too troublesome (but users could add an\n        arbitrary logging uid to differentiate), but we'll put it there anyway for now...\n\n        Args:\n            scrapli_conn: scrapli connection to fetch data from\n\n        Returns:\n            str: instance name to use for the connection\n\n        Raises:\n            N/A\n\n        \"\"\"\n        instance_name = (\n            f\"{scrapli_conn.host}:{scrapli_conn.port}:\"\n            f\"{scrapli_conn.transport.__class__.__name__}:\"\n            f\"{scrapli_conn.logger.extra.get('uid', '')}\"  # type:ignore\n        )\n        similar_instance_names = [\n            inst_name for inst_name in self.wrapped_instances if inst_name.startswith(instance_name)\n        ]\n        instance_name = f\"{instance_name}:{len(similar_instance_names)}\"\n        return instance_name\n\n    @staticmethod\n    def create_connection_profile(scrapli_conn: Union[AsyncDriver, Driver]) -&gt; ConnectionProfile:\n\"\"\"\n        Record connection information\n\n        Args:\n            scrapli_conn: scrapli connection to fetch data from\n\n        Returns:\n            ConnectionProfile: recorded connection profile\n\n        Raises:\n            N/A\n\n        \"\"\"\n        recorded_connection_profile = ConnectionProfile(\n            host=scrapli_conn.host,\n            port=scrapli_conn.port,\n            auth_username=scrapli_conn.auth_username,\n            auth_password=bool(scrapli_conn.auth_password),\n            auth_private_key=scrapli_conn.auth_private_key,\n            auth_private_key_passphrase=bool(scrapli_conn.auth_private_key_passphrase),\n            auth_bypass=scrapli_conn.auth_bypass,\n            transport=scrapli_conn.transport_name,\n        )\n\n        if isinstance(scrapli_conn, NetworkDriver):\n            recorded_connection_profile.auth_secondary = bool(scrapli_conn.auth_secondary)\n\n        return recorded_connection_profile\n\n    def _session_exists(self) -&gt; bool:\n\"\"\"\n        Check if a session file already exists\n\n        Args:\n            N/A\n\n        Returns:\n            bool:\n\n        Raises:\n            N/A\n\n        \"\"\"\n        if Path(f\"{self.session_directory}/{self.session_name}.yaml\").is_file():\n            return True\n        return False\n\n    def _serialize(self) -&gt; Dict[str, Any]:\n\"\"\"\n        Serialize in memory session data into a yaml-friendly output\n\n        Args:\n            N/A\n\n        Returns:\n             None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        instance_replay_sessions = {}\n\n        for instance_name, replay_instance in self.wrapped_instances.items():\n            instance_read_log = replay_instance.read_log\n            instance_write_log = replay_instance.write_log\n\n            read_log_len = instance_read_log.tell()\n            instance_read_log.seek(0)\n\n            instance_replay_session: Dict[str, Any] = {}\n            instance_replay_sessions[instance_name] = instance_replay_session\n\n            try:\n                instance_replay_session[\"connection_profile\"] = asdict(\n                    replay_instance.connection_profile\n                )\n            except TypeError:\n                # connection was already open so we couldn't patch it\n                instance_replay_session[\"connection_profile\"] = {}\n\n            instance_replay_session[\"interactions\"] = []\n\n            # all things after the \"initial output\" is an \"interaction\"\n            previous_read_to_position = 0\n            for write_data in instance_write_log:\n                write_input, redacted, read_to_position = write_data\n\n                channel_bytes_output = instance_read_log.read(\n                    read_to_position - previous_read_to_position\n                )\n                try:\n                    channel_output = channel_bytes_output.decode()\n                except UnicodeDecodeError:\n                    # unclear if this will ever be a problem... leaving it in this try/except for\n                    # posterity...\n                    channel_output = channel_bytes_output.decode(errors=\"ignore\")\n\n                # replace any output w/ the scrapli cfg replace pattern\n                channel_output = re.sub(\n                    pattern=SCRAPLI_CFG_SESSION_PATTERN,\n                    repl=\"__SCRAPLI_CFG_SESSION_NAME__\",\n                    string=channel_output,\n                )\n\n                instance_replay_session[\"interactions\"].append(\n                    {\n                        \"channel_output\": channel_output,\n                        \"expected_channel_input\": write_input if not redacted else \"REDACTED\",\n                        \"expected_channel_input_redacted\": redacted,\n                    }\n                )\n                previous_read_to_position = read_to_position\n\n            if previous_read_to_position != read_log_len:\n                # we can end up w/ \"extra\" data if we dont close the connection -- as in scrapli\n                # will have read one more thing than it wrote -- so we check to see if there is\n                # remaining read log data, and if so add one final interaction\n                instance_replay_session[\"interactions\"].append(\n                    {\n                        \"channel_output\": instance_read_log.read().decode(),\n                        \"expected_channel_input\": None,\n                        \"expected_channel_input_redacted\": False,\n                    }\n                )\n\n        return instance_replay_sessions\n\n    def _save(self) -&gt; None:\n\"\"\"\n        Save the contents of a session\n\n        Args:\n            N/A\n\n        Returns:\n             None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        with open(f\"{self.session_directory}/{self.session_name}.yaml\", \"w\", encoding=\"utf-8\") as f:\n            YAML.indent(mapping=2, sequence=4, offset=2)\n            YAML.dump(self._serialize(), f)\n</code></pre>"},{"location":"reference/replay/replay/#replay.replay.ScrapliReplay.__aenter__","title":"<code>__aenter__() -&gt; None</code>  <code>async</code>","text":"<p>Enter method for context manager</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>replay/replay.py</code> <pre><code>async def __aenter__(self) -&gt; None:\n\"\"\"\n    Enter method for context manager\n\n    Args:\n        N/A\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n\n    async def patched_open(cls: AsyncDriver) -&gt; None:\n\"\"\"\n        Patched AsyncDriver.open method\n\n        Patched at the driver and dealing w/ the on open/auth things as this way we never have\n        to think about which transport is being used\n\n        Args:\n            cls: scrapli Drive self\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        instance_name = self.create_instance_name(scrapli_conn=cls)\n\n        cls.channel.open()\n        self._channel_close = cls.channel.close\n\n        connection_profile = self.create_connection_profile(scrapli_conn=cls)\n        instance_object = ScrapliReplayInstance(\n            replay_mode=self.replay_mode,\n            connection_profile=connection_profile,\n            replay_session=self.replay_session.get(instance_name, {}),\n        )\n        self.wrapped_instances[instance_name] = instance_object\n\n        if self.replay_mode == ReplayMode.REPLAY:\n            instance_object.setup_async_replay_mode(scrapli_conn=cls)\n        else:\n            if self._block_network is True:\n                # if block network is true and we got here then there is no session recorded, so\n                # we need to skip this test\n                pytest.skip(\n                    \"scrapli-replay block-network is True, no session recorded, \"\n                    \"skipping test...\"\n                )\n\n            # if we are not in replay mode, we are in record or overwrite (same/same) so setup\n            # the record read/write channel methods and then do \"normal\" stuff\n            instance_object.setup_async_record_mode(scrapli_conn=cls)\n            await cls.transport.open()\n\n        cls._pre_open_closing_log(closing=False)  # pylint: disable=W0212\n\n        if (\n            cls.transport_name\n            in (\n                \"telnet\",\n                \"asynctelnet\",\n            )\n            and not cls.auth_bypass\n        ):\n            await cls.channel.channel_authenticate_telnet(\n                auth_username=cls.auth_username, auth_password=cls.auth_password\n            )\n            if self.replay_mode == ReplayMode.RECORD:\n                instance_object.telnet_patch_update_log(auth_username=cls.auth_username)\n\n        if cls.on_open:\n            await cls.on_open(cls)\n\n        cls._post_open_closing_log(closing=False)  # pylint: disable=W0212\n\n    self._patched_open = mock.patch.object(\n        scrapli.driver.base.async_driver.AsyncDriver, \"open\", new=patched_open\n    )\n    self._patched_open.start()\n</code></pre>"},{"location":"reference/replay/replay/#replay.replay.ScrapliReplay.__aexit__","title":"<code>__aexit__(exception_type: Optional[Type[BaseException]], exception_value: Optional[BaseException], traceback: Optional[TracebackType]) -&gt; None</code>  <code>async</code>","text":"<p>Exit method to cleanup for async context manager</p> <p>Parameters:</p> Name Type Description Default <code>exception_type</code> <code>Optional[Type[BaseException]]</code> <p>exception type being raised</p> required <code>exception_value</code> <code>Optional[BaseException]</code> <p>message from exception being raised</p> required <code>traceback</code> <code>Optional[TracebackType]</code> <p>traceback from exception being raised</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>ScrapliReplayException</code> <p>if patched open is none for some reason</p> Source code in <code>replay/replay.py</code> <pre><code>async def __aexit__(\n    self,\n    exception_type: Optional[Type[BaseException]],\n    exception_value: Optional[BaseException],\n    traceback: Optional[TracebackType],\n) -&gt; None:\n\"\"\"\n    Exit method to cleanup for async context manager\n\n    Args:\n        exception_type: exception type being raised\n        exception_value: message from exception being raised\n        traceback: traceback from exception being raised\n\n    Returns:\n        None\n\n    Raises:\n        ScrapliReplayException: if patched open is none for some reason\n\n    \"\"\"\n    if not self._patched_open:\n        raise ScrapliReplayException(\n            \"patched open is None, but we are in exit... this should never happen, definitely \"\n            \"a bug\"\n        )\n\n    self._patched_open.stop()\n\n    if self.replay_mode in (ReplayMode.RECORD, ReplayMode.OVERWRITE):\n        self._save()\n\n    if self._channel_close:\n        self._channel_close()\n</code></pre>"},{"location":"reference/replay/replay/#replay.replay.ScrapliReplay.__call__","title":"<code>__call__(wrapped_func: Callable[..., Any]) -&gt; Callable[..., Any]</code>","text":"<p>Use ScrapliReplay as a decorator</p> <p>Decide if the wrapped function is sync or async and wrap that function/coroutine in context manager of self</p> <p>Parameters:</p> Name Type Description Default <code>wrapped_func</code> <code>Callable[..., Any]</code> <p>function being decorated</p> required <p>Returns:</p> Name Type Description <code>decorate</code> <code>Callable[..., Any]</code> <p>decorated func</p> Source code in <code>replay/replay.py</code> <pre><code>def __call__(self, wrapped_func: Callable[..., Any]) -&gt; Callable[..., Any]:\n\"\"\"\n    Use ScrapliReplay as a decorator\n\n    Decide if the wrapped function is sync or async and wrap that function/coroutine in context\n    manager of self\n\n    Args:\n        wrapped_func: function being decorated\n\n    Returns:\n        decorate: decorated func\n\n    Raises:\n        N/A\n\n    \"\"\"\n    if asyncio.iscoroutinefunction(wrapped_func):\n\n        async def decorate(*args: Any, **kwargs: Any) -&gt; Any:\n            async with self:\n                return await wrapped_func(*args, **kwargs)\n\n    else:\n        # ignoring type error:\n        # \"All conditional function variants must have identical signatures\"\n        # one is sync one is async so never going to be identical here!\n        def decorate(*args: Any, **kwargs: Any) -&gt; Any:  # type: ignore\n            with self:\n                return wrapped_func(*args, **kwargs)\n\n    return decorate\n</code></pre>"},{"location":"reference/replay/replay/#replay.replay.ScrapliReplay.__enter__","title":"<code>__enter__() -&gt; None</code>","text":"<p>Enter method for context manager</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>replay/replay.py</code> <pre><code>def __enter__(self) -&gt; None:\n\"\"\"\n    Enter method for context manager\n\n    Args:\n        N/A\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n\n    def patched_open(cls: Driver) -&gt; None:\n\"\"\"\n        Patched Driver.open method\n\n        Patched at the driver and dealing w/ the on open/auth things as this way we never have\n        to think about which transport is being used\n\n        Args:\n            cls: scrapli Drive self\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        instance_name = self.create_instance_name(scrapli_conn=cls)\n\n        cls.channel.open()\n        self._channel_close = cls.channel.close\n\n        connection_profile = self.create_connection_profile(scrapli_conn=cls)\n        instance_object = ScrapliReplayInstance(\n            replay_mode=self.replay_mode,\n            connection_profile=connection_profile,\n            replay_session=self.replay_session.get(instance_name, {}),\n        )\n        self.wrapped_instances[instance_name] = instance_object\n\n        if self.replay_mode == ReplayMode.REPLAY:\n            instance_object.setup_replay_mode(scrapli_conn=cls)\n        else:\n            if self._block_network is True:\n                # if block network is true and we got here then there is no session recorded, so\n                # we need to skip this test\n                pytest.skip(\n                    \"scrapli-replay block-network is True, no session recorded, \"\n                    \"skipping test...\"\n                )\n\n            # if we are not in replay mode, we are in record or overwrite (same/same) so setup\n            # the record read/write channel methods and then do \"normal\" stuff\n            instance_object.setup_record_mode(scrapli_conn=cls)\n            cls.transport.open()\n\n        cls._pre_open_closing_log(closing=False)  # pylint: disable=W0212\n\n        if cls.transport_name in (\"system\",) and not cls.auth_bypass:\n            cls.channel.channel_authenticate_ssh(\n                auth_password=cls.auth_password,\n                auth_private_key_passphrase=cls.auth_private_key_passphrase,\n            )\n        if (\n            cls.transport_name\n            in (\n                \"telnet\",\n                \"asynctelnet\",\n            )\n            and not cls.auth_bypass\n        ):\n            cls.channel.channel_authenticate_telnet(\n                auth_username=cls.auth_username, auth_password=cls.auth_password\n            )\n            if self.replay_mode == ReplayMode.RECORD:\n                instance_object.telnet_patch_update_log(auth_username=cls.auth_username)\n\n        if cls.on_open:\n            cls.on_open(cls)\n\n        cls._post_open_closing_log(closing=False)  # pylint: disable=W0212\n\n    self._patched_open = mock.patch.object(\n        target=scrapli.driver.base.sync_driver.Driver, attribute=\"open\", new=patched_open\n    )\n    self._patched_open.start()\n</code></pre>"},{"location":"reference/replay/replay/#replay.replay.ScrapliReplay.__exit__","title":"<code>__exit__(exception_type: Optional[Type[BaseException]], exception_value: Optional[BaseException], traceback: Optional[TracebackType]) -&gt; None</code>","text":"<p>Exit method to cleanup for context manager</p> <p>Parameters:</p> Name Type Description Default <code>exception_type</code> <code>Optional[Type[BaseException]]</code> <p>exception type being raised</p> required <code>exception_value</code> <code>Optional[BaseException]</code> <p>message from exception being raised</p> required <code>traceback</code> <code>Optional[TracebackType]</code> <p>traceback from exception being raised</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>ScrapliReplayException</code> <p>if patched open is none for some reason</p> Source code in <code>replay/replay.py</code> <pre><code>def __exit__(\n    self,\n    exception_type: Optional[Type[BaseException]],\n    exception_value: Optional[BaseException],\n    traceback: Optional[TracebackType],\n) -&gt; None:\n\"\"\"\n    Exit method to cleanup for context manager\n\n    Args:\n        exception_type: exception type being raised\n        exception_value: message from exception being raised\n        traceback: traceback from exception being raised\n\n    Returns:\n        None\n\n    Raises:\n        ScrapliReplayException: if patched open is none for some reason\n\n    \"\"\"\n    if not self._patched_open:\n        raise ScrapliReplayException(\n            \"patched open is None, but we are in exit... this should never happen, definitely \"\n            \"a bug\"\n        )\n\n    self._patched_open.stop()\n\n    if self.replay_mode in (ReplayMode.RECORD, ReplayMode.OVERWRITE):\n        self._save()\n\n    if self._channel_close:\n        self._channel_close()\n</code></pre>"},{"location":"reference/replay/replay/#replay.replay.ScrapliReplay.__init__","title":"<code>__init__(*, session_directory: Optional[str] = None, session_name: Optional[str] = None, replay_mode: str = 'record', block_network: bool = False) -&gt; None</code>","text":"<p>Scrapli replay</p> <p>Parameters:</p> Name Type Description Default <code>session_directory</code> <code>Optional[str]</code> <p>directory to write session data to</p> <code>None</code> <code>session_name</code> <code>Optional[str]</code> <p>name of session to write out</p> <code>None</code> <code>replay_mode</code> <code>str</code> <p>replay mode to use</p> <code>'record'</code> <code>block_network</code> <code>bool</code> <p>if set to True, no network connections will be made, though any stored sessions will be ran normally</p> <code>False</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>ScrapliReplayException</code> <p>if invalid replay mode provided</p> Source code in <code>replay/replay.py</code> <pre><code>def __init__(\n    self,\n    *,\n    session_directory: Optional[str] = None,\n    session_name: Optional[str] = None,\n    replay_mode: str = \"record\",\n    block_network: bool = False,\n) -&gt; None:\n\"\"\"\n    Scrapli replay\n\n    Args:\n        session_directory: directory to write session data to\n        session_name: name of session to write out\n        replay_mode: replay mode to use\n        block_network: if set to True, no network connections will be made, though any stored\n            sessions will be ran normally\n\n    Returns:\n        None\n\n    Raises:\n        ScrapliReplayException: if invalid replay mode provided\n\n    \"\"\"\n    if session_directory is None or not Path(session_directory).is_dir():\n        self.session_directory = Path.cwd()\n    else:\n        self.session_directory = Path(session_directory)\n\n    # session name will generally come from pytest test name, but for ad-hoc use it can be\n    # auto-generated w/ timestamp\n    self.session_name = (\n        session_name or f\"scrapli_replay_session_{round(datetime.now().timestamp())}\"\n    )\n\n    if replay_mode not in (\n        \"record\",\n        \"replay\",\n        \"overwrite\",\n    ):\n        raise ScrapliReplayException(\"replay mode invalid\")\n\n    if replay_mode == \"record\" and self._session_exists():\n        print(\n            \"session exists but replay mode is not set to overwrite, using replay mode 'replay'\"\n        )\n        replay_mode = \"replay\"\n    elif not self._session_exists():\n        replay_mode = \"record\"\n\n    self.replay_mode = ReplayMode[replay_mode.upper()]\n\n    self.replay_session: Dict[str, Any] = {}\n    if self.replay_mode == ReplayMode.REPLAY:\n        with open(\n            f\"{self.session_directory}/{self.session_name}.yaml\", \"r\", encoding=\"utf-8\"\n        ) as f:\n            self.replay_session = YAML.load(f)\n        # if we open a session and there are no interactions recorded for any of the hosts then\n        # something is not right -- we will need to re-record a session\n        if not all(\n            instance_session.get(\"interactions\", None)\n            for instance_session in self.replay_session.values()\n        ):\n            self.replay_mode = ReplayMode.RECORD\n\n    self._block_network = block_network\n    self._patched_open: Optional[mock._patch[Any]] = None  # noqa\n    self.wrapped_instances: Dict[str, ScrapliReplayInstance] = {}\n\n    self._channel_close: Optional[Callable[[], None]] = None\n</code></pre>"},{"location":"reference/replay/replay/#replay.replay.ScrapliReplay.create_connection_profile","title":"<code>create_connection_profile(scrapli_conn: Union[AsyncDriver, Driver]) -&gt; ConnectionProfile</code>  <code>staticmethod</code>","text":"<p>Record connection information</p> <p>Parameters:</p> Name Type Description Default <code>scrapli_conn</code> <code>Union[AsyncDriver, Driver]</code> <p>scrapli connection to fetch data from</p> required <p>Returns:</p> Name Type Description <code>ConnectionProfile</code> <code>ConnectionProfile</code> <p>recorded connection profile</p> Source code in <code>replay/replay.py</code> <pre><code>@staticmethod\ndef create_connection_profile(scrapli_conn: Union[AsyncDriver, Driver]) -&gt; ConnectionProfile:\n\"\"\"\n    Record connection information\n\n    Args:\n        scrapli_conn: scrapli connection to fetch data from\n\n    Returns:\n        ConnectionProfile: recorded connection profile\n\n    Raises:\n        N/A\n\n    \"\"\"\n    recorded_connection_profile = ConnectionProfile(\n        host=scrapli_conn.host,\n        port=scrapli_conn.port,\n        auth_username=scrapli_conn.auth_username,\n        auth_password=bool(scrapli_conn.auth_password),\n        auth_private_key=scrapli_conn.auth_private_key,\n        auth_private_key_passphrase=bool(scrapli_conn.auth_private_key_passphrase),\n        auth_bypass=scrapli_conn.auth_bypass,\n        transport=scrapli_conn.transport_name,\n    )\n\n    if isinstance(scrapli_conn, NetworkDriver):\n        recorded_connection_profile.auth_secondary = bool(scrapli_conn.auth_secondary)\n\n    return recorded_connection_profile\n</code></pre>"},{"location":"reference/replay/replay/#replay.replay.ScrapliReplay.create_instance_name","title":"<code>create_instance_name(scrapli_conn: Union[AsyncDriver, Driver]) -&gt; str</code>","text":"<p>Create as unique as possible instance name for a given connection</p> <p>Since hash cant be relied on to between python executions we need to have some way to have a decent idea about what connection is what... using the host and port is maybe not enough as a user may have multiple connections to the same device in a test session. Adding in the transport might help (maybe one is ssh one is netconf or telnet), but still not 100%... Adding in the logging uid is handy, but only if the user set one, so we also will tack on an extra field basically counting how many of the same connections we've seen. We may not support multiple connections because it may be too troublesome (but users could add an arbitrary logging uid to differentiate), but we'll put it there anyway for now...</p> <p>Parameters:</p> Name Type Description Default <code>scrapli_conn</code> <code>Union[AsyncDriver, Driver]</code> <p>scrapli connection to fetch data from</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>instance name to use for the connection</p> Source code in <code>replay/replay.py</code> <pre><code>def create_instance_name(self, scrapli_conn: Union[AsyncDriver, Driver]) -&gt; str:\n\"\"\"\n    Create as unique as possible instance name for a given connection\n\n    Since hash cant be relied on to between python executions we need to have some way to have a\n    decent idea about what connection is what... using the host and port is maybe not enough as\n    a user may have multiple connections to the same device in a test session. Adding in the\n    transport *might* help (maybe one is ssh one is netconf or telnet), but still not 100%...\n    Adding in the logging uid is handy, but only if the user set one, so we also will tack on\n    an extra field basically counting how many of the same connections we've seen. We *may* not\n    support multiple connections because it may be too troublesome (but users could add an\n    arbitrary logging uid to differentiate), but we'll put it there anyway for now...\n\n    Args:\n        scrapli_conn: scrapli connection to fetch data from\n\n    Returns:\n        str: instance name to use for the connection\n\n    Raises:\n        N/A\n\n    \"\"\"\n    instance_name = (\n        f\"{scrapli_conn.host}:{scrapli_conn.port}:\"\n        f\"{scrapli_conn.transport.__class__.__name__}:\"\n        f\"{scrapli_conn.logger.extra.get('uid', '')}\"  # type:ignore\n    )\n    similar_instance_names = [\n        inst_name for inst_name in self.wrapped_instances if inst_name.startswith(instance_name)\n    ]\n    instance_name = f\"{instance_name}:{len(similar_instance_names)}\"\n    return instance_name\n</code></pre>"},{"location":"reference/replay/replay/#replay.replay.ScrapliReplayInstance","title":"<code>ScrapliReplayInstance</code>","text":"Source code in <code>replay/replay.py</code> <pre><code>class ScrapliReplayInstance:\n    def __init__(\n        self,\n        *,\n        replay_mode: ReplayMode,\n        connection_profile: ConnectionProfile,\n        replay_session: Optional[Dict[str, Any]] = None,\n    ) -&gt; None:\n\"\"\"\n        Scrapli replay\n\n        Args:\n            replay_mode: replay mode to use\n            connection_profile: connection profile object\n            replay_session: dict of replay session (used in replay mode, ignored in record mode)\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        self.replay_mode = replay_mode\n        self.connection_profile = connection_profile\n\n        self.replay_session = replay_session or {}\n\n        self.read_log = BytesIO()\n        self.write_log: List[Tuple[str, bool, int]] = []\n\n        self._scrapli_cfg_session = \"\"\n\n    def _common_replay_mode(self) -&gt; Tuple[Iterator[str], Iterator[Tuple[str, bool]]]:\n\"\"\"\n        Handle common replay mode parsing of saved session data (common between sync/async)\n\n        Args:\n            N/A\n\n        Returns:\n            Tuple[Iterator[str], Iterator[Tuple[str, bool]]]: returns the device_outputs and\n                scrapli_inputs iterators to use in the replay read/write methods\n\n        Raises:\n            ScrapliReplayConnectionProfileError: if recorded connection profile does not match the\n                actual connection profile\n\n        \"\"\"\n        actual_connection_profile = ConnectionProfile(**self.replay_session[\"connection_profile\"])\n\n        if actual_connection_profile != self.connection_profile:\n            msg = \"recorded connection profile does not match current connection profile\"\n            raise ScrapliReplayConnectionProfileError(msg)\n\n        device_outputs = iter(\n            [interaction[\"channel_output\"] for interaction in self.replay_session[\"interactions\"]]\n        )\n        scrapli_inputs = iter(\n            [\n                (\n                    interaction[\"expected_channel_input\"],\n                    interaction[\"expected_channel_input_redacted\"],\n                )\n                for interaction in self.replay_session[\"interactions\"]\n            ]\n        )\n        return device_outputs, scrapli_inputs\n\n    def setup_async_replay_mode(self, scrapli_conn: AsyncDriver) -&gt; None:\n\"\"\"\n        Patch scrapli Channel read/write methods in \"replay\" mode\n\n        Args:\n            scrapli_conn: scrapli connection to fetch data from\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        device_outputs, scrapli_inputs = self._common_replay_mode()\n        self._patch_async_read_replay(scrapli_conn=scrapli_conn, device_outputs=device_outputs)\n        self._patch_write_replay(scrapli_conn=scrapli_conn, scrapli_inputs=scrapli_inputs)\n\n    def setup_replay_mode(self, scrapli_conn: Driver) -&gt; None:\n\"\"\"\n        Patch scrapli Channel read/write methods in \"replay\" mode\n\n        Args:\n            scrapli_conn: scrapli connection to fetch data from\n\n        Returns:\n            None\n\n        Raises:\n            N/Ah\n\n        \"\"\"\n        device_outputs, scrapli_inputs = self._common_replay_mode()\n        self._patch_read_replay(scrapli_conn=scrapli_conn, device_outputs=device_outputs)\n        self._patch_write_replay(scrapli_conn=scrapli_conn, scrapli_inputs=scrapli_inputs)\n\n    def _patch_async_read_replay(\n        self, scrapli_conn: AsyncDriver, device_outputs: Iterator[str]\n    ) -&gt; None:\n\"\"\"\n        Patch scrapli AsyncChannel read method in \"replay\" mode\n\n        Args:\n            scrapli_conn: scrapli connection to fetch data from\n            device_outputs: iterator of inputs that the read method should return for the \"fake\"\n                connection\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n\n        async def patched_read(cls: AsyncChannel) -&gt; bytes:\n\"\"\"\n            Patched AsyncChannel.read method\n\n            Args:\n                cls: scrapli Channel self\n\n            Returns:\n                bytes: bytes read from teh channel\n\n            Raises:\n                ScrapliReplayException: if there are no more outputs from the session to replay\n\n            \"\"\"\n            try:\n                buf = next(device_outputs).encode()\n\n                # if we see this string we know we actually need to ship out the current scrapli cfg\n                # session name that we capture during the replay write method\n                if b\"__SCRAPLI_CFG_SESSION_NAME__\" in buf and self._scrapli_cfg_session:\n                    buf = self._scrapli_cfg_session.encode()\n                    self._scrapli_cfg_session = \"\"\n\n            except StopIteration as exc:\n                msg = \"No more device outputs to replay\"\n                raise ScrapliReplayException(msg) from exc\n\n            cls.logger.debug(f\"read: {repr(buf)}\")\n\n            if cls.channel_log:\n                cls.channel_log.write(buf)\n\n            if b\"\\x1b\" in buf.lower():\n                buf = cls._strip_ansi(buf=buf)  # pylint: disable=W0212\n\n            return buf\n\n        scrapli_conn.channel.read = types.MethodType(  # type: ignore\n            patched_read, scrapli_conn.channel\n        )\n\n    def _patch_read_replay(self, scrapli_conn: Driver, device_outputs: Iterator[str]) -&gt; None:\n\"\"\"\n        Patch scrapli Channel read method in \"replay\" mode\n\n        Args:\n            scrapli_conn: scrapli connection to fetch data from\n            device_outputs: iterator of inputs that the read method should return for the \"fake\"\n                connection\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n\n        def patched_read(cls: Channel) -&gt; bytes:\n\"\"\"\n            Patched Channel.read method\n\n            Args:\n                cls: scrapli Channel self\n\n            Returns:\n                bytes: bytes read form the channel\n\n            Raises:\n                ScrapliReplayException: if there are no more outputs from the session to replay\n\n            \"\"\"\n            try:\n                buf = next(device_outputs).encode()\n\n                # if we see this string we know we actually need to ship out the current scrapli cfg\n                # session name that we capture during the replay write method\n                if b\"__SCRAPLI_CFG_SESSION_NAME__\" in buf and self._scrapli_cfg_session:\n                    buf = self._scrapli_cfg_session.encode()\n                    self._scrapli_cfg_session = \"\"\n\n            except StopIteration as exc:\n                msg = \"No more device outputs to replay\"\n                raise ScrapliReplayException(msg) from exc\n\n            cls.logger.debug(f\"read: {repr(buf)}\")\n\n            if cls.channel_log:\n                cls.channel_log.write(buf)\n\n            if b\"\\x1b\" in buf.lower():\n                buf = cls._strip_ansi(buf=buf)  # pylint: disable=W0212\n\n            return buf\n\n        scrapli_conn.channel.read = types.MethodType(  # type: ignore\n            patched_read, scrapli_conn.channel\n        )\n\n    def _patch_write_replay(\n        self, scrapli_conn: Union[AsyncDriver, Driver], scrapli_inputs: Iterator[Tuple[str, bool]]\n    ) -&gt; None:\n\"\"\"\n        Patch scrapli Channel write method in \"replay\" mode\n\n        Args:\n            scrapli_conn: scrapli connection to fetch data from\n            scrapli_inputs: inputs to assert are true that scrapli should be sending\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n\n        def patched_write(cls: BaseChannel, channel_input: str, redacted: bool = False) -&gt; None:\n\"\"\"\n            Patched Channel.write method\n\n            Args:\n                cls: scrapli Channel self\n                channel_input: input to send to the channel\n                redacted: if input should be redacted from log\n\n            Returns:\n                None\n\n            Raises:\n                ScrapliReplayExpectedInputError: if actual input does not match expected input\n\n            \"\"\"\n            expected_input, expected_redacted = next(scrapli_inputs)\n\n            if redacted is True:\n                _channel_input = \"REDACTED\"\n            elif re.search(pattern=SCRAPLI_CFG_SESSION_PATTERN, string=channel_input):\n                _channel_input = re.sub(\n                    pattern=SCRAPLI_CFG_SESSION_PATTERN,\n                    string=channel_input,\n                    repl=\"__SCRAPLI_CFG_SESSION_NAME__\",\n                )\n                # if we see a scrapli cfg session in the replay we have to store it as it has a\n                # timestamp -- we need to replay this back so scrapli doesnt break\n                self._scrapli_cfg_session = channel_input\n            else:\n                _channel_input = channel_input\n\n            if not all((expected_input == _channel_input, expected_redacted == redacted)):\n                msg = \"expected channel input does not match actual channel input\"\n                raise ScrapliReplayExpectedInputError(msg)\n\n            log_output = \"REDACTED\" if redacted else repr(channel_input)\n            cls.logger.debug(f\"write: {log_output}\")\n\n        scrapli_conn.channel.write = types.MethodType(  # type: ignore\n            patched_write, scrapli_conn.channel\n        )\n\n    def setup_async_record_mode(self, scrapli_conn: AsyncDriver) -&gt; None:\n\"\"\"\n        Patch scrapli AsyncChannel read and write methods in \"record\" mode\n\n        Args:\n            scrapli_conn: scrapli connection to fetch data from\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        self._patch_async_read_record(scrapli_conn=scrapli_conn)\n        self._patch_write_record(scrapli_conn=scrapli_conn)\n\n    def setup_record_mode(self, scrapli_conn: Driver) -&gt; None:\n\"\"\"\n        Patch scrapli Channel read and write methods in \"record\" mode\n\n        Args:\n            scrapli_conn: scrapli connection to fetch data from\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        self._patch_read_record(scrapli_conn=scrapli_conn)\n        self._patch_write_record(scrapli_conn=scrapli_conn)\n\n    def _patch_async_read_record(self, scrapli_conn: AsyncDriver) -&gt; None:\n\"\"\"\n        Patch scrapli AsyncChannel read method in \"record\" mode\n\n        Args:\n            scrapli_conn: scrapli connection to fetch data from\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n\n        async def patched_read(cls: AsyncChannel) -&gt; bytes:\n\"\"\"\n            Patched Channel.read method\n\n            Args:\n                cls: scrapli Channel self\n\n            Returns:\n                bytes: bytes read\n\n            Raises:\n                N/A\n\n            \"\"\"\n            buf: bytes = await cls.transport.read()\n            buf = buf.replace(b\"\\r\", b\"\")\n\n            cls.logger.debug(f\"read: {repr(buf)}\")\n\n            if cls.channel_log:\n                cls.channel_log.write(buf)\n\n            if b\"\\x1b\" in buf.lower():\n                buf = cls._strip_ansi(buf=buf)  # pylint: disable=W0212\n\n            self.read_log.write(buf)\n\n            return buf\n\n        scrapli_conn.channel.read = types.MethodType(  # type: ignore\n            patched_read, scrapli_conn.channel\n        )\n\n    def _patch_read_record(self, scrapli_conn: Driver) -&gt; None:\n\"\"\"\n        Patch scrapli Channel read method in \"record\" mode\n\n        Args:\n            scrapli_conn: scrapli connection to fetch data from\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n\n        def patched_read(cls: Channel) -&gt; bytes:\n\"\"\"\n            Patched Channel.read method\n\n            Args:\n                cls: scrapli Channel self\n\n            Returns:\n                bytes: bytes read\n\n            Raises:\n                N/A\n\n            \"\"\"\n            buf: bytes = cls.transport.read()\n            buf = buf.replace(b\"\\r\", b\"\")\n\n            cls.logger.debug(f\"read: {repr(buf)}\")\n\n            if cls.channel_log:\n                cls.channel_log.write(buf)\n\n            if b\"\\x1b\" in buf.lower():\n                buf = cls._strip_ansi(buf=buf)  # pylint: disable=W0212\n\n            self.read_log.write(buf)\n\n            return buf\n\n        scrapli_conn.channel.read = types.MethodType(  # type: ignore\n            patched_read, scrapli_conn.channel\n        )\n\n    def _patch_write_record(\n        self,\n        scrapli_conn: Union[AsyncDriver, Driver],\n    ) -&gt; None:\n\"\"\"\n        Patch scrapli Channel write method in \"record\" mode\n\n        Args:\n            scrapli_conn: scrapli connection to fetch data from\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n\n        def patched_write(cls: BaseChannel, channel_input: str, redacted: bool = False) -&gt; None:\n\"\"\"\n            Patched Channel.write method\n\n            Args:\n                cls: scrapli Channel self\n                channel_input: input to send to the channel\n                redacted: if input should be redacted from log\n\n            Returns:\n                None\n\n            Raises:\n                N/A\n\n            \"\"\"\n            _channel_input = re.sub(\n                pattern=SCRAPLI_CFG_SESSION_PATTERN,\n                repl=\"__SCRAPLI_CFG_SESSION_NAME__\",\n                string=channel_input,\n            )\n\n            self.write_log.append((_channel_input, redacted, self.read_log.tell()))\n\n            log_output = \"REDACTED\" if redacted else repr(channel_input)\n            cls.logger.debug(f\"write: {log_output}\")\n\n            cls.transport.write(channel_input=channel_input.encode())\n\n        scrapli_conn.channel.write = types.MethodType(  # type: ignore\n            patched_write, scrapli_conn.channel\n        )\n\n    def telnet_patch_update_log(self, auth_username: str) -&gt; None:\n\"\"\"\n        Patch the read log for telnet connections\n\n        This method removes \"leading dead space\" and any extra returns/dead space between user and\n        password and the first prompt/banner showing up. This only is necessary for telnet conns.\n\n        Args:\n             auth_username: username from the patched scrapli object\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        updatedwrite_log = []\n        for write_log_entry in self.write_log:\n            updatedwrite_log.append(write_log_entry)\n            if write_log_entry[1] is True:\n                break\n        # append the *last* entry in the write log back to the updated list -- this will\n        # get us reading up through the banner/initial prompt\n        updatedwrite_log.append(self.write_log[-1])\n\n        # for telnet connections we may have some \"dead space\" (empty reads) at the\n        # beginning of the interactions, get rid of that as it is not needed here\n        index = 0\n        for index, write_log_entry in enumerate(updatedwrite_log):\n            if write_log_entry[0] == auth_username:\n                # we've got the index of the updated write log starting at the username\n                # we know we can slice everything off before this now\n                break\n        updatedwrite_log = updatedwrite_log[index:]\n\n        # finally update the replay class write log w/ our modified version\n        self.write_log = updatedwrite_log\n</code></pre>"},{"location":"reference/replay/replay/#replay.replay.ScrapliReplayInstance.__init__","title":"<code>__init__(*, replay_mode: ReplayMode, connection_profile: ConnectionProfile, replay_session: Optional[Dict[str, Any]] = None) -&gt; None</code>","text":"<p>Scrapli replay</p> <p>Parameters:</p> Name Type Description Default <code>replay_mode</code> <code>ReplayMode</code> <p>replay mode to use</p> required <code>connection_profile</code> <code>ConnectionProfile</code> <p>connection profile object</p> required <code>replay_session</code> <code>Optional[Dict[str, Any]]</code> <p>dict of replay session (used in replay mode, ignored in record mode)</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>replay/replay.py</code> <pre><code>def __init__(\n    self,\n    *,\n    replay_mode: ReplayMode,\n    connection_profile: ConnectionProfile,\n    replay_session: Optional[Dict[str, Any]] = None,\n) -&gt; None:\n\"\"\"\n    Scrapli replay\n\n    Args:\n        replay_mode: replay mode to use\n        connection_profile: connection profile object\n        replay_session: dict of replay session (used in replay mode, ignored in record mode)\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    self.replay_mode = replay_mode\n    self.connection_profile = connection_profile\n\n    self.replay_session = replay_session or {}\n\n    self.read_log = BytesIO()\n    self.write_log: List[Tuple[str, bool, int]] = []\n\n    self._scrapli_cfg_session = \"\"\n</code></pre>"},{"location":"reference/replay/replay/#replay.replay.ScrapliReplayInstance.setup_async_record_mode","title":"<code>setup_async_record_mode(scrapli_conn: AsyncDriver) -&gt; None</code>","text":"<p>Patch scrapli AsyncChannel read and write methods in \"record\" mode</p> <p>Parameters:</p> Name Type Description Default <code>scrapli_conn</code> <code>AsyncDriver</code> <p>scrapli connection to fetch data from</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>replay/replay.py</code> <pre><code>def setup_async_record_mode(self, scrapli_conn: AsyncDriver) -&gt; None:\n\"\"\"\n    Patch scrapli AsyncChannel read and write methods in \"record\" mode\n\n    Args:\n        scrapli_conn: scrapli connection to fetch data from\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    self._patch_async_read_record(scrapli_conn=scrapli_conn)\n    self._patch_write_record(scrapli_conn=scrapli_conn)\n</code></pre>"},{"location":"reference/replay/replay/#replay.replay.ScrapliReplayInstance.setup_async_replay_mode","title":"<code>setup_async_replay_mode(scrapli_conn: AsyncDriver) -&gt; None</code>","text":"<p>Patch scrapli Channel read/write methods in \"replay\" mode</p> <p>Parameters:</p> Name Type Description Default <code>scrapli_conn</code> <code>AsyncDriver</code> <p>scrapli connection to fetch data from</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>replay/replay.py</code> <pre><code>def setup_async_replay_mode(self, scrapli_conn: AsyncDriver) -&gt; None:\n\"\"\"\n    Patch scrapli Channel read/write methods in \"replay\" mode\n\n    Args:\n        scrapli_conn: scrapli connection to fetch data from\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    device_outputs, scrapli_inputs = self._common_replay_mode()\n    self._patch_async_read_replay(scrapli_conn=scrapli_conn, device_outputs=device_outputs)\n    self._patch_write_replay(scrapli_conn=scrapli_conn, scrapli_inputs=scrapli_inputs)\n</code></pre>"},{"location":"reference/replay/replay/#replay.replay.ScrapliReplayInstance.setup_record_mode","title":"<code>setup_record_mode(scrapli_conn: Driver) -&gt; None</code>","text":"<p>Patch scrapli Channel read and write methods in \"record\" mode</p> <p>Parameters:</p> Name Type Description Default <code>scrapli_conn</code> <code>Driver</code> <p>scrapli connection to fetch data from</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>replay/replay.py</code> <pre><code>def setup_record_mode(self, scrapli_conn: Driver) -&gt; None:\n\"\"\"\n    Patch scrapli Channel read and write methods in \"record\" mode\n\n    Args:\n        scrapli_conn: scrapli connection to fetch data from\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    self._patch_read_record(scrapli_conn=scrapli_conn)\n    self._patch_write_record(scrapli_conn=scrapli_conn)\n</code></pre>"},{"location":"reference/replay/replay/#replay.replay.ScrapliReplayInstance.setup_replay_mode","title":"<code>setup_replay_mode(scrapli_conn: Driver) -&gt; None</code>","text":"<p>Patch scrapli Channel read/write methods in \"replay\" mode</p> <p>Parameters:</p> Name Type Description Default <code>scrapli_conn</code> <code>Driver</code> <p>scrapli connection to fetch data from</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>replay/replay.py</code> <pre><code>def setup_replay_mode(self, scrapli_conn: Driver) -&gt; None:\n\"\"\"\n    Patch scrapli Channel read/write methods in \"replay\" mode\n\n    Args:\n        scrapli_conn: scrapli connection to fetch data from\n\n    Returns:\n        None\n\n    Raises:\n        N/Ah\n\n    \"\"\"\n    device_outputs, scrapli_inputs = self._common_replay_mode()\n    self._patch_read_replay(scrapli_conn=scrapli_conn, device_outputs=device_outputs)\n    self._patch_write_replay(scrapli_conn=scrapli_conn, scrapli_inputs=scrapli_inputs)\n</code></pre>"},{"location":"reference/replay/replay/#replay.replay.ScrapliReplayInstance.telnet_patch_update_log","title":"<code>telnet_patch_update_log(auth_username: str) -&gt; None</code>","text":"<p>Patch the read log for telnet connections</p> <p>This method removes \"leading dead space\" and any extra returns/dead space between user and password and the first prompt/banner showing up. This only is necessary for telnet conns.</p> <p>Parameters:</p> Name Type Description Default <code>auth_username</code> <code>str</code> <p>username from the patched scrapli object</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>replay/replay.py</code> <pre><code>def telnet_patch_update_log(self, auth_username: str) -&gt; None:\n\"\"\"\n    Patch the read log for telnet connections\n\n    This method removes \"leading dead space\" and any extra returns/dead space between user and\n    password and the first prompt/banner showing up. This only is necessary for telnet conns.\n\n    Args:\n         auth_username: username from the patched scrapli object\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    updatedwrite_log = []\n    for write_log_entry in self.write_log:\n        updatedwrite_log.append(write_log_entry)\n        if write_log_entry[1] is True:\n            break\n    # append the *last* entry in the write log back to the updated list -- this will\n    # get us reading up through the banner/initial prompt\n    updatedwrite_log.append(self.write_log[-1])\n\n    # for telnet connections we may have some \"dead space\" (empty reads) at the\n    # beginning of the interactions, get rid of that as it is not needed here\n    index = 0\n    for index, write_log_entry in enumerate(updatedwrite_log):\n        if write_log_entry[0] == auth_username:\n            # we've got the index of the updated write log starting at the username\n            # we know we can slice everything off before this now\n            break\n    updatedwrite_log = updatedwrite_log[index:]\n\n    # finally update the replay class write log w/ our modified version\n    self.write_log = updatedwrite_log\n</code></pre>"},{"location":"reference/server/","title":"Index","text":"<p>scrapli_replay.server</p>"},{"location":"reference/server/collector/","title":"Collector","text":"<p>scrapli_replay.server.collector</p>"},{"location":"reference/server/collector/#server.collector.ScrapliCollector","title":"<code>ScrapliCollector</code>","text":"Source code in <code>server/collector.py</code> <pre><code>class ScrapliCollector:\n    def __init__(\n        self,\n        channel_inputs: List[str],\n        interact_events: List[List[Tuple[str, str, bool]]],\n        paging_indicator: str,\n        paging_escape_string: str = \"\\x1b\",\n        scrapli_connection: Optional[NetworkDriver] = None,\n        collector_session_filename: str = \"scrapli_replay_collector_session.yaml\",\n        **kwargs: Dict[str, Any],\n    ) -&gt; None:\n\"\"\"\n        Scrapli Collector Class\n\n        Patches scrapli so that we can record the connection inputs and outputs from the channel\n\n        Args:\n            channel_inputs: list of channel inputs to record\n            interact_events: list of interact events to record\n            paging_indicator: string that indicates when the device is prompting for user input to\n                continue paging the output\n            paging_escape_string: string to use to escape the paging prompt\n            scrapli_connection: already instantiated scrapli connection -- you can pass this or just\n                the kwargs necessary to instantiate one for you\n            collector_session_filename: name of file to save collector session output to\n            kwargs: kwargs to instantiate scrapli connection, *must* include platform as this will\n                instantiate the connection via `Scrapli` factory class!\n\n        Returns:\n            None\n\n        Raises:\n            ScrapliReplayException: if no valid scrapli connection or connection data present\n\n        \"\"\"\n        logger.debug(\"creating scrapli replay collector\")\n\n        self.channel_inputs = channel_inputs\n        self.interact_events = interact_events\n        self.paging_indicator = paging_indicator\n        self.paging_escape_string = paging_escape_string\n\n        self.collector_session_filename = collector_session_filename\n\n        self.channel_log = BytesIO()\n        # making the channel log unclose-able so we can retain the channel log even throughout\n        # connections being closed\n        self.channel_log.close = lambda: None  # type: ignore\n\n        if scrapli_connection:\n            logger.debug(\"scrapli connection provided\")\n            self.scrapli_connection = scrapli_connection\n            self.scrapli_connection._base_channel_args.channel_log = self.channel_log\n\n            if self.scrapli_connection.isalive():\n                # want to close it so we can reset the on open (paging stuff)\n                self.scrapli_connection.close()\n\n        else:\n            logger.debug(\"no scrapli connection provided, building one from kwargs\")\n            if not kwargs.get(\"platform\"):\n                msg = \"must provide 'platform' as a kwarg if you dont provide a connection object!\"\n                logger.critical(msg)\n                raise ScrapliReplayException(msg)\n\n            if kwargs.pop(\"channel_log\", None):\n                user_warning(\n                    title=\"Ignored argument!\",\n                    message=\"channel_log arg provided, replacing with ScrapliCollector channel_log\",\n                )\n\n            self.scrapli_connection = Scrapli(\n                channel_log=self.channel_log,\n                **kwargs,  # type: ignore\n            )\n\n        self.scrapli_connection_original_timeout_transport = (\n            self.scrapli_connection.timeout_transport\n        )\n        # update the channel to be an instance of the ScrapliCollectorChannel\n        self.scrapli_connection.channel = ScrapliCollectorChannel(\n            transport=self.scrapli_connection.transport,\n            base_channel_args=self.scrapli_connection._base_channel_args,\n        )\n\n        # store the \"normal\" default desired privilege level\n        self.scrapli_connection_default_desired_privilege_level = (\n            self.scrapli_connection.default_desired_privilege_level\n        )\n\n        # store and reset the on_open/on_close to None so we can manage when we want to disable\n        # paging and such\n        self.scrapli_connection_standard_on_open = self.scrapli_connection.on_open\n        self.scrapli_connection_standard_on_close = self.scrapli_connection.on_close\n        self.scrapli_connection.on_open = None\n        self.scrapli_connection.on_close = None\n\n        # bool to just indicate if we have ran the on open stuff\n        self.on_open_enabled = False\n        self.on_open_inputs: List[str] = []\n\n        self.on_close_inputs: List[str] = []\n\n        # flag to indicate if we have collected priv prompts yet\n        self.collected_priv_prompts = False\n\n        # Future: support recording any login auth/banner stuff too\n\n        platform_privilege_levels = self.scrapli_connection.privilege_levels.keys()\n        self.initial_privilege_level = \"\"\n        self.privilege_level_prompts: Dict[str, str] = {\n            privilege_level_name: \"\" for privilege_level_name in platform_privilege_levels\n        }\n\n        # commands captured from driver privilege levels for escalate/deescalate\n        self._privilege_escalate_inputs: List[str] = []\n        self._privilege_deescalate_inputs: List[str] = []\n        self._interact_privilege_escalations: List[List[Tuple[str, str, bool]]] = []\n\n        self.events: Dict[str, Dict[str, Dict[str, Union[StandardEvent, InteractiveEvent]]]] = {\n            privilege_level_name: {\"pre_on_open\": {}, \"post_on_open\": {}}\n            for privilege_level_name in platform_privilege_levels\n        }\n        self.dumpable_events: Dict[str, Dict[str, Dict[str, Any]]] = {\n            privilege_level_name: {\"pre_on_open\": {}, \"post_on_open\": {}}\n            for privilege_level_name in platform_privilege_levels\n        }\n\n        # this would be similar to the events but for an unknown input, like we have in the v2 thing\n        self.unknown_events: Dict[str, Dict[str, Optional[StandardEvent]]] = {\n            privilege_level_name: {\"pre_on_open\": None, \"post_on_open\": None}\n            for privilege_level_name in platform_privilege_levels\n        }\n        self.dumpable_unknown_events: Dict[str, Dict[str, Optional[Any]]] = {\n            privilege_level_name: {\"pre_on_open\": None, \"post_on_open\": None}\n            for privilege_level_name in platform_privilege_levels\n        }\n\n        # this is a list of all possible prompts -- because we are going to use send and expect we\n        # need to be able to expect any prompt OR the paging pattern... so after open and we collect\n        # the prompts for each priv level, we can build this list\n        self.all_expected_patterns = [self.paging_indicator]\n\n        self._determine_privilege_inputs()\n\n    def open(self) -&gt; None:\n\"\"\"\n        Open the Collector and the underlying scrapli connection\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n        self.scrapli_connection.open()\n\n        if not self.initial_privilege_level:\n            # only need to fetch this on the initial open, not for subsequent opens when we need\n            # to reconnect!\n            logger.debug(\n                \"no initial privilege level set, must be first open... setting initial privilege \"\n                \"level\"\n            )\n            self.initial_privilege_level = self._get_current_privilege_level_name()\n\n    def close(self) -&gt; None:\n\"\"\"\n        Close the Collector and the underlying scrapli connection\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n        self.scrapli_connection.close()\n\n    def _determine_privilege_inputs(self) -&gt; None:\n\"\"\"\n        Private method to figure out what the privilege escalation/deescalation inputs are\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n        logger.debug(\"building all privilege level inputs/interactions from scrapli driver\")\n\n        self._privilege_escalate_inputs = [\n            priv.escalate\n            for priv in self.scrapli_connection.privilege_levels.values()\n            if not priv.escalate_auth and priv.escalate\n        ]\n        self._privilege_deescalate_inputs = [\n            priv.deescalate\n            for priv in self.scrapli_connection.privilege_levels.values()\n            if priv.deescalate\n        ]\n\n        interact_privilege_escalations_levels = [\n            priv\n            for priv in self.scrapli_connection.privilege_levels.values()\n            if priv.escalate_auth and priv.escalate_prompt\n        ]\n        self._interact_privilege_escalations = [\n            [\n                (priv.escalate, priv.escalate_prompt, False),\n                (\"__AUTH_SECONDARY__\", priv.pattern, True),\n            ]\n            for priv in interact_privilege_escalations_levels\n        ]\n\n    def _get_current_privilege_level_name(self, prompt: Optional[str] = None) -&gt; str:\n\"\"\"\n        Convenience method to fetch current privilege level name from the current prompt\n\n        Args:\n            prompt: prompt pattern to use, if not supplied, we'll fetch current prompt\n\n        Returns:\n            str: string name of current privilege level\n\n        Raises:\n            N/A\n\n        \"\"\"\n        if not prompt:\n            prompt = self.scrapli_connection.get_prompt()\n        priv_name: str = self.scrapli_connection._determine_current_priv(prompt)[0]\n        return priv_name\n\n    def _collect_privilege_prompts(self) -&gt; None:\n\"\"\"\n        Private method to get all of the prompts for each priv of the underlying device\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n        for priv_level in self.privilege_level_prompts:\n            logger.info(f\"collecting prompt for priv level {priv_level}\")\n            self.scrapli_connection.acquire_priv(priv_level)\n            self.privilege_level_prompts[priv_level] = self.scrapli_connection.get_prompt()\n\n        self.collected_priv_prompts = True\n\n    def _extend_all_expected_prompts(self) -&gt; None:\n\"\"\"\n        Extend the \"all_expected_prompts\" to include all the captured privilege level prompts\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            ScrapliReplayException: if privilege patterns aren't collected before running this\n\n        \"\"\"\n        if not self.collected_priv_prompts:\n            msg = (\n                \"attempting to build all expected prompts pattern, but have not collected privilege\"\n                \" level prompts yet, failing\"\n            )\n            logger.critical(msg)\n            raise ScrapliReplayException(msg)\n\n        self.all_expected_patterns.extend(\n            [prompt for _, prompt in self.privilege_level_prompts.items()]\n        )\n\n    @staticmethod\n    def _strip_remaining_ansi(raw_output: bytes) -&gt; str:\n\"\"\"\n        Strip remaining ansi chars and decode bytes to string\n\n        Unclear why as it seems like `_strip_ansi` in scrapli core channel should handle this, but\n        some ansi characters do *not* get stripped out, handle them here. Note that this seems to\n        be an EOS specific thing as the other \"core\" platforms dont plop ansi into the output.\n\n        Args:\n            raw_output: channel output to remove remaining ansi chars from\n\n        Returns:\n            : channel output w/ leading newline removed\n\n        Raises:\n            N/A\n\n        \"\"\"\n        if b\"\\x1b\" in raw_output:\n            # genuinely dont know what the `&gt;` one is... in theory the `=` one is some screen set\n            # argument?\n            raw_output = raw_output.replace(b\"\\x1b=\", b\"\")\n            raw_output = raw_output.replace(b\"\\x1b&gt;\", b\"\")\n\n        channel_output = raw_output.decode()\n\n        return channel_output\n\n    @staticmethod\n    def _strip_leading_newline(channel_output: str) -&gt; str:\n\"\"\"\n        Remove a single leading newline if present\n\n        Args:\n            channel_output: channel output to remove single leading newline from\n\n        Returns:\n            str: channel output w/ leading newline removed\n\n        Raises:\n            N/A\n\n        \"\"\"\n        if channel_output.startswith(\"\\n\"):\n            channel_output = channel_output[1:]\n\n        return channel_output\n\n    def _collect_on_open_inputs(self) -&gt; None:\n\"\"\"\n        Private method to figure out what the \"on_open\" commands are\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n        self.scrapli_connection.acquire_priv(\n            self.scrapli_connection_default_desired_privilege_level\n        )\n\n        logger.info(\"collecting on open inputs\")\n\n        self.scrapli_connection.channel = cast(\n            ScrapliCollectorChannel, self.scrapli_connection.channel\n        )\n        starting_write_log_count = len(self.scrapli_connection.channel.captured_writes)\n        self.scrapli_connection_standard_on_open(self.scrapli_connection)  # type: ignore\n        ending_write_log_count = len(self.scrapli_connection.channel.captured_writes)\n\n        write_log_slice = ending_write_log_count - starting_write_log_count\n        on_open_writes = self.scrapli_connection.channel.captured_writes[-write_log_slice:]\n\n        # all we need to do here is to fetch the commands that were sent, then we can \"handle\" them\n        # with the standard collection (since we already handle disconnects there), we can assume\n        # with reasonable safety that each command will really come in \"pairs\" -- the command itself\n        # and a return. after reversing the list we can just get every other list item\n        on_open_writes.reverse()\n        self.on_open_inputs = on_open_writes[1::2]\n\n    def _collect_on_close_inputs(self) -&gt; None:\n\"\"\"\n        Private method to figure out what the \"on_close\" commands are\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n        self.scrapli_connection.acquire_priv(\n            self.scrapli_connection_default_desired_privilege_level\n        )\n\n        logger.info(\"collecting on close inputs\")\n\n        self.scrapli_connection.channel = cast(\n            ScrapliCollectorChannel, self.scrapli_connection.channel\n        )\n        starting_write_log_count = len(self.scrapli_connection.channel.captured_writes)\n        self.scrapli_connection_standard_on_close(self.scrapli_connection)  # type: ignore\n        ending_write_log_count = len(self.scrapli_connection.channel.captured_writes)\n\n        write_log_slice = ending_write_log_count - starting_write_log_count\n        on_close_writes = self.scrapli_connection.channel.captured_writes[-write_log_slice:]\n\n        # all we need to do here is to fetch the commands that were sent, then we can \"handle\" them\n        # with the standard collection (since we already handle disconnects there), we can assume\n        # with reasonable safety that each command will really come in \"pairs\" -- the command itself\n        # and a return. after reversing the list we can just get every other list item\n        on_close_writes.reverse()\n        self.on_close_inputs = on_close_writes[1::2]\n\n        # the connection *should* have closed at this point, so we'll check that and reopen, because\n        # we didnt do a \"normal\" close (at the driver level) we maybe cant check with \"isalive()\"\n        try:\n            self.scrapli_connection.get_prompt()\n        except ScrapliConnectionError:\n            logger.debug(\"connection closed, re-opening\")\n            self.open()\n\n    def _collect_standard_event(self, channel_input: str) -&gt; None:\n\"\"\"\n        Private method to execute and record commands provided to the Collector\n\n        Runs the commands at *all* priv levels so that we can build more context about how the\n        device behaves\n\n        Args:\n            channel_input: input to send\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n        on_open_enabled_key = \"post_on_open\" if self.on_open_enabled else \"pre_on_open\"\n\n        for priv_level in self.scrapli_connection.privilege_levels:\n            logger.info(f\"collecting input {channel_input} for priv level {priv_level}\")\n\n            self.scrapli_connection.acquire_priv(priv_level)\n\n            try:\n                raw_output, _ = self.scrapli_connection.channel.send_input_and_read(\n                    channel_input=channel_input,\n                    expected_outputs=self.all_expected_patterns,\n                    # especially nxos in vrouter is v v v slow....\n                    read_duration=READ_DURATION,\n                )\n            except ScrapliConnectionError:\n                logger.debug(\"connection closed connection, documenting and re-opening\")\n                closes_connection = True\n                channel_output = \"__CLOSES_CONNECTION__\"\n                returns_prompt = False\n                # because we use \"send_input_and_read\" if we lose the connection during this the\n                # transport timeout will have been set to 2s or something during the send input\n                # and read event, we want to make sure to reset it back to \"normal\" after this\n                # failure\n                self.scrapli_connection.timeout_transport = (\n                    self.scrapli_connection_original_timeout_transport\n                )\n                # reopen the connection so things can continue!\n                self.open()\n            else:\n                closes_connection = False\n                channel_output = self._strip_remaining_ansi(raw_output=raw_output)\n                returns_prompt = True\n                if self.paging_indicator.encode() in raw_output:\n                    logger.debug(\"encountered paging indicator, sending escape string\")\n                    self.scrapli_connection.channel.write(channel_input=self.paging_escape_string)\n                    self.scrapli_connection.channel.send_return()\n                    returns_prompt = False\n\n            result_privilege_level = self._get_current_privilege_level_name()\n\n            final_channel_output = self._strip_leading_newline(channel_output=channel_output)\n\n            channel_input_event = StandardEvent(\n                channel_output=final_channel_output,\n                result_privilege_level=result_privilege_level,\n                returns_prompt=returns_prompt,\n                closes_connection=closes_connection,\n            )\n\n            self.events[priv_level][on_open_enabled_key][channel_input] = channel_input_event\n\n    def _collect_interactive_event_hidden_input(\n        self, channel_input: str, channel_response: str\n    ) -&gt; bytes:\n\"\"\"\n        Send \"hidden\" input during interactive event collection\n\n        Args:\n            channel_input: input to send\n            channel_response: response to expect\n\n        Returns:\n            bytes: raw bytes read from channel\n\n        Raises:\n            None\n\n        \"\"\"\n        _channel_input = channel_input\n        if channel_input == \"__AUTH_SECONDARY__\":\n            _channel_input = self.scrapli_connection.auth_secondary\n        self.scrapli_connection.channel.write(channel_input=_channel_input)\n        self.scrapli_connection.channel.send_return()\n        bytes_channel_outputs = [\n            channel_output.encode() for channel_output in self.all_expected_patterns\n        ]\n        bytes_channel_outputs.append(channel_response.encode())\n        raw_output: bytes = self.scrapli_connection.channel._read_until_prompt_or_time(\n            channel_outputs=bytes_channel_outputs,\n            # especially nxos in vrouter is v v v slow....\n            read_duration=READ_DURATION,\n        )\n        return raw_output\n\n    def _collect_interactive_event_standard_input(\n        self, channel_input: str, channel_response: str\n    ) -&gt; bytes:\n\"\"\"\n        Send \"standard\" input during interactive event collection\n\n        Args:\n            channel_input: input to send\n            channel_response: response to expect\n\n        Returns:\n            bytes: raw bytes read from channel\n\n        Raises:\n            None\n\n        \"\"\"\n        all_patterns_and_expected_interact_prompt = copy(self.all_expected_patterns)\n        all_patterns_and_expected_interact_prompt.append(channel_response)\n\n        raw_output, _ = self.scrapli_connection.channel.send_input_and_read(\n            channel_input=channel_input,\n            expected_outputs=all_patterns_and_expected_interact_prompt,\n            # especially nxos in vrouter is v v v slow....\n            read_duration=READ_DURATION,\n        )\n\n        if channel_input == \"\":\n            # if we just send a return, we'll end up w/ two newlines before the prompt or whatever\n            # output we get, so let's remove the leading devices comms_return_char\n            slice_length = len(self.scrapli_connection.comms_return_char)\n            final_channel_output = raw_output[slice_length:]\n            return final_channel_output  # type: ignore\n        return raw_output  # type: ignore\n\n    def _collect_interactive_parse_channel_input(\n        self, channel_input: str, hidden_input: bool\n    ) -&gt; str:\n\"\"\"\n        Parse the response to put in the StandardEvent\n\n        Args:\n            channel_input: input to send\n            hidden_input: bool if channel_input was hidden\n\n        Returns:\n            str: channel input to put into collection dict\n\n        Raises:\n            None\n\n        \"\"\"\n        _channel_input = channel_input\n        if hidden_input and channel_input == \"__AUTH_SECONDARY__\":\n            _channel_input = \"__AUTH_SECONDARY__\"\n        elif hidden_input:\n            _channel_input = \"__REDACTED__\"\n        elif not channel_input:\n            _channel_input = self.scrapli_connection.comms_return_char\n        return _channel_input\n\n    def _collect_interactive_event(self, interact_event: List[Tuple[str, str, bool]]) -&gt; None:\n\"\"\"\n        Private method to execute and record all interactive commands provided to the Collector\n\n        Runs the commands at *all* priv levels so that we can build more context about how the\n        device behaves\n\n        Args:\n            interact_event: interactive event to capture\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n        on_open_enabled_key = \"post_on_open\" if self.on_open_enabled else \"pre_on_open\"\n\n        for priv_level in self.scrapli_connection.privilege_levels:\n            self.scrapli_connection.acquire_priv(priv_level)\n\n            logger.info(\n                f\"collecting interactive event {interact_event} for priv level {priv_level}\"\n            )\n\n            interactive_event = InteractiveEvent(event_steps=[])\n            initiating_channel_input = interact_event[0][0]\n\n            for interact_step in interact_event:\n                channel_input = interact_step[0]\n                channel_response = interact_step[1]\n                try:\n                    hidden_input = interact_step[2]\n                except IndexError:\n                    hidden_input = False\n\n                if hidden_input:\n                    raw_output = self._collect_interactive_event_hidden_input(\n                        channel_input=channel_input, channel_response=channel_response\n                    )\n                else:\n                    raw_output = self._collect_interactive_event_standard_input(\n                        channel_input=channel_input, channel_response=channel_response\n                    )\n\n                returns_prompt = True\n                if self.paging_indicator.encode() in raw_output:\n                    self.scrapli_connection.channel.write(channel_input=self.paging_escape_string)\n                    self.scrapli_connection.channel.send_return()\n                    returns_prompt = False\n\n                _channel_input = self._collect_interactive_parse_channel_input(\n                    channel_input=channel_input, hidden_input=hidden_input\n                )\n\n                final_channel_output = self._strip_leading_newline(\n                    channel_output=raw_output.decode()\n                )\n\n                step = InteractStep(\n                    channel_input=_channel_input,\n                    channel_output=final_channel_output,\n                    hidden_input=hidden_input,\n                    returns_prompt=returns_prompt,\n                )\n\n                interactive_event.event_steps.append(step)  # type: ignore\n\n                if returns_prompt is False:\n                    # probably not likely to happen during interactive... but maybe?\n                    break\n\n                if any(pattern in raw_output.decode() for pattern in self.all_expected_patterns):\n                    # we are done w/ the \"event\" because we are back at a prompt we know\n                    break\n\n            interactive_event.result_privilege_level = self._get_current_privilege_level_name()\n            self.events[priv_level][on_open_enabled_key][\n                initiating_channel_input\n            ] = interactive_event\n\n    def _collect_unknown_events(self) -&gt; None:\n\"\"\"\n        Private method to execute and record \"unknown\" commands\n\n        Runs the commands at *all* priv levels so that we can build more context about how the\n        device behaves\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n        on_open_enabled_key = \"post_on_open\" if self.on_open_enabled else \"pre_on_open\"\n\n        for priv_level in self.scrapli_connection.privilege_levels:\n            self.scrapli_connection.acquire_priv(priv_level)\n\n            logger.info(f\"collecting unknown input for priv level {priv_level}\")\n\n            try:\n                raw_output, _ = self.scrapli_connection.channel.send_input_and_read(\n                    channel_input=\"__UNKNOWN_INPUT__\", expected_outputs=self.all_expected_patterns\n                )\n            except ScrapliConnectionError:\n                closes_connection = True\n                channel_output = \"__CLOSES_CONNECTION__\"\n                returns_prompt = False\n                # reopen the connection so things can continue!\n                self.open()\n            else:\n                closes_connection = False\n                channel_output = self._strip_remaining_ansi(raw_output=raw_output)\n                returns_prompt = True\n                if self.paging_indicator.encode() in raw_output:\n                    self.scrapli_connection.channel.write(channel_input=self.paging_escape_string)\n                    self.scrapli_connection.channel.send_return()\n                    returns_prompt = False\n\n            result_privilege_level = self._get_current_privilege_level_name()\n\n            final_channel_output = self._strip_leading_newline(channel_output=channel_output)\n\n            channel_unknown_input_event = StandardEvent(\n                channel_output=final_channel_output,\n                result_privilege_level=result_privilege_level,\n                returns_prompt=returns_prompt,\n                closes_connection=closes_connection,\n            )\n\n            self.unknown_events[priv_level][on_open_enabled_key] = channel_unknown_input_event\n\n    def _collect_priv_and_open_close(self) -&gt; None:\n\"\"\"\n        Collect privilege escalation/deescalation and on open/close inputs/outputs\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        self._collect_on_open_inputs()\n        for on_open_input in self.on_open_inputs:\n            self._collect_standard_event(channel_input=on_open_input)\n\n        self._collect_on_close_inputs()\n        for on_close_input in self.on_close_inputs:\n            self._collect_standard_event(channel_input=on_close_input)\n\n        for privilege_escalate_input in self._privilege_escalate_inputs:\n            self._collect_standard_event(channel_input=privilege_escalate_input)\n\n        for privilege_deescalate_input in self._privilege_deescalate_inputs:\n            self._collect_standard_event(channel_input=privilege_deescalate_input)\n\n        for interact_privilege_event in self._interact_privilege_escalations:\n            self._collect_interactive_event(interact_event=interact_privilege_event)\n\n    def _collect(self) -&gt; None:\n\"\"\"\n        Private method to execute all the \"standard\" and \"interactive\" collections\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n        self._collect_unknown_events()\n\n        for channel_input in self.channel_inputs:\n            self._collect_standard_event(channel_input=channel_input)\n\n        for interact_event in self.interact_events:\n            self._collect_interactive_event(interact_event=interact_event)\n\n    def collect(self) -&gt; None:\n\"\"\"\n        Primary public collection method\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n        self._collect_privilege_prompts()\n        self._extend_all_expected_prompts()\n\n        self._collect_priv_and_open_close()\n\n        if isinstance(self.scrapli_connection, EOSDriver):\n            # arista will leave paging enabled even after you exit a connection... kinda throws\n            # things off! so we'll put it back... hate having one off things like this but not sure\n            # there is another easy fix\n            self.scrapli_connection.send_command(command=\"no terminal length\")\n\n        self._collect()\n\n        # close the connection, and reassign the \"normal\" on open so we can capture everything\n        # with \"on_open\" things done (paging disabled and whatever else)\n        self.close()\n        self.scrapli_connection.on_open = self.scrapli_connection_standard_on_open\n        self.scrapli_connection.on_close = self.scrapli_connection_standard_on_close\n        self.open()\n        self.on_open_enabled = True\n\n        self._collect_priv_and_open_close()\n        self._collect()\n\n    def _serialize(self) -&gt; None:\n\"\"\"\n        Serialize the collected data so it can be dumped to yaml nicely\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n        logger.debug(\"serializing collected inputs to be yaml friendly\")\n\n        for privilege_level in self.events:\n            for on_open_state in self.events[privilege_level]:\n                for channel_input in self.events[privilege_level][on_open_state]:\n                    self.dumpable_events[privilege_level][on_open_state][channel_input] = asdict(\n                        self.events[privilege_level][on_open_state][channel_input]\n                    )\n                    self.dumpable_events[privilege_level][on_open_state][channel_input][\"type\"] = (\n                        \"standard\"\n                        if isinstance(\n                            self.events[privilege_level][on_open_state][channel_input],\n                            StandardEvent,\n                        )\n                        else \"interactive\"\n                    )\n\n        for privilege_level in self.unknown_events:\n            for on_open_state in self.unknown_events[privilege_level]:\n                self.dumpable_unknown_events[privilege_level][on_open_state] = asdict(\n                    self.unknown_events[privilege_level][on_open_state]  # type: ignore\n                )\n\n    def dump(self) -&gt; None:\n\"\"\"\n        Primary public dump method to dump collected data out to yaml\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            None\n\n        \"\"\"\n        self._serialize()\n\n        logger.debug(\"dumping collected inputs to yaml\")\n\n        dumpable_dict: Dict[str, Any] = {}\n        dumpable_dict[\"events\"] = self.dumpable_events\n        dumpable_dict[\"unknown_events\"] = self.dumpable_unknown_events\n        dumpable_dict[\"initial_privilege_level\"] = self.initial_privilege_level\n        dumpable_dict[\"privilege_level_prompts\"] = self.privilege_level_prompts\n        dumpable_dict[\"on_open_inputs\"] = self.on_open_inputs\n\n        with open(self.collector_session_filename, \"w\", encoding=\"utf-8\") as f:\n            yaml = YAML()\n            yaml.indent(mapping=2, sequence=4, offset=2)\n            yaml.dump(dumpable_dict, f)\n</code></pre>"},{"location":"reference/server/collector/#server.collector.ScrapliCollector.__init__","title":"<code>__init__(channel_inputs: List[str], interact_events: List[List[Tuple[str, str, bool]]], paging_indicator: str, paging_escape_string: str = '\\x1b', scrapli_connection: Optional[NetworkDriver] = None, collector_session_filename: str = 'scrapli_replay_collector_session.yaml', **kwargs: Dict[str, Any]) -&gt; None</code>","text":"<p>Scrapli Collector Class</p> <p>Patches scrapli so that we can record the connection inputs and outputs from the channel</p> <p>Parameters:</p> Name Type Description Default <code>channel_inputs</code> <code>List[str]</code> <p>list of channel inputs to record</p> required <code>interact_events</code> <code>List[List[Tuple[str, str, bool]]]</code> <p>list of interact events to record</p> required <code>paging_indicator</code> <code>str</code> <p>string that indicates when the device is prompting for user input to continue paging the output</p> required <code>paging_escape_string</code> <code>str</code> <p>string to use to escape the paging prompt</p> <code>'\\x1b'</code> <code>scrapli_connection</code> <code>Optional[NetworkDriver]</code> <p>already instantiated scrapli connection -- you can pass this or just the kwargs necessary to instantiate one for you</p> <code>None</code> <code>collector_session_filename</code> <code>str</code> <p>name of file to save collector session output to</p> <code>'scrapli_replay_collector_session.yaml'</code> <code>kwargs</code> <p>kwargs to instantiate scrapli connection, must include platform as this will instantiate the connection via <code>Scrapli</code> factory class!</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>ScrapliReplayException</code> <p>if no valid scrapli connection or connection data present</p> Source code in <code>server/collector.py</code> <pre><code>def __init__(\n    self,\n    channel_inputs: List[str],\n    interact_events: List[List[Tuple[str, str, bool]]],\n    paging_indicator: str,\n    paging_escape_string: str = \"\\x1b\",\n    scrapli_connection: Optional[NetworkDriver] = None,\n    collector_session_filename: str = \"scrapli_replay_collector_session.yaml\",\n    **kwargs: Dict[str, Any],\n) -&gt; None:\n\"\"\"\n    Scrapli Collector Class\n\n    Patches scrapli so that we can record the connection inputs and outputs from the channel\n\n    Args:\n        channel_inputs: list of channel inputs to record\n        interact_events: list of interact events to record\n        paging_indicator: string that indicates when the device is prompting for user input to\n            continue paging the output\n        paging_escape_string: string to use to escape the paging prompt\n        scrapli_connection: already instantiated scrapli connection -- you can pass this or just\n            the kwargs necessary to instantiate one for you\n        collector_session_filename: name of file to save collector session output to\n        kwargs: kwargs to instantiate scrapli connection, *must* include platform as this will\n            instantiate the connection via `Scrapli` factory class!\n\n    Returns:\n        None\n\n    Raises:\n        ScrapliReplayException: if no valid scrapli connection or connection data present\n\n    \"\"\"\n    logger.debug(\"creating scrapli replay collector\")\n\n    self.channel_inputs = channel_inputs\n    self.interact_events = interact_events\n    self.paging_indicator = paging_indicator\n    self.paging_escape_string = paging_escape_string\n\n    self.collector_session_filename = collector_session_filename\n\n    self.channel_log = BytesIO()\n    # making the channel log unclose-able so we can retain the channel log even throughout\n    # connections being closed\n    self.channel_log.close = lambda: None  # type: ignore\n\n    if scrapli_connection:\n        logger.debug(\"scrapli connection provided\")\n        self.scrapli_connection = scrapli_connection\n        self.scrapli_connection._base_channel_args.channel_log = self.channel_log\n\n        if self.scrapli_connection.isalive():\n            # want to close it so we can reset the on open (paging stuff)\n            self.scrapli_connection.close()\n\n    else:\n        logger.debug(\"no scrapli connection provided, building one from kwargs\")\n        if not kwargs.get(\"platform\"):\n            msg = \"must provide 'platform' as a kwarg if you dont provide a connection object!\"\n            logger.critical(msg)\n            raise ScrapliReplayException(msg)\n\n        if kwargs.pop(\"channel_log\", None):\n            user_warning(\n                title=\"Ignored argument!\",\n                message=\"channel_log arg provided, replacing with ScrapliCollector channel_log\",\n            )\n\n        self.scrapli_connection = Scrapli(\n            channel_log=self.channel_log,\n            **kwargs,  # type: ignore\n        )\n\n    self.scrapli_connection_original_timeout_transport = (\n        self.scrapli_connection.timeout_transport\n    )\n    # update the channel to be an instance of the ScrapliCollectorChannel\n    self.scrapli_connection.channel = ScrapliCollectorChannel(\n        transport=self.scrapli_connection.transport,\n        base_channel_args=self.scrapli_connection._base_channel_args,\n    )\n\n    # store the \"normal\" default desired privilege level\n    self.scrapli_connection_default_desired_privilege_level = (\n        self.scrapli_connection.default_desired_privilege_level\n    )\n\n    # store and reset the on_open/on_close to None so we can manage when we want to disable\n    # paging and such\n    self.scrapli_connection_standard_on_open = self.scrapli_connection.on_open\n    self.scrapli_connection_standard_on_close = self.scrapli_connection.on_close\n    self.scrapli_connection.on_open = None\n    self.scrapli_connection.on_close = None\n\n    # bool to just indicate if we have ran the on open stuff\n    self.on_open_enabled = False\n    self.on_open_inputs: List[str] = []\n\n    self.on_close_inputs: List[str] = []\n\n    # flag to indicate if we have collected priv prompts yet\n    self.collected_priv_prompts = False\n\n    # Future: support recording any login auth/banner stuff too\n\n    platform_privilege_levels = self.scrapli_connection.privilege_levels.keys()\n    self.initial_privilege_level = \"\"\n    self.privilege_level_prompts: Dict[str, str] = {\n        privilege_level_name: \"\" for privilege_level_name in platform_privilege_levels\n    }\n\n    # commands captured from driver privilege levels for escalate/deescalate\n    self._privilege_escalate_inputs: List[str] = []\n    self._privilege_deescalate_inputs: List[str] = []\n    self._interact_privilege_escalations: List[List[Tuple[str, str, bool]]] = []\n\n    self.events: Dict[str, Dict[str, Dict[str, Union[StandardEvent, InteractiveEvent]]]] = {\n        privilege_level_name: {\"pre_on_open\": {}, \"post_on_open\": {}}\n        for privilege_level_name in platform_privilege_levels\n    }\n    self.dumpable_events: Dict[str, Dict[str, Dict[str, Any]]] = {\n        privilege_level_name: {\"pre_on_open\": {}, \"post_on_open\": {}}\n        for privilege_level_name in platform_privilege_levels\n    }\n\n    # this would be similar to the events but for an unknown input, like we have in the v2 thing\n    self.unknown_events: Dict[str, Dict[str, Optional[StandardEvent]]] = {\n        privilege_level_name: {\"pre_on_open\": None, \"post_on_open\": None}\n        for privilege_level_name in platform_privilege_levels\n    }\n    self.dumpable_unknown_events: Dict[str, Dict[str, Optional[Any]]] = {\n        privilege_level_name: {\"pre_on_open\": None, \"post_on_open\": None}\n        for privilege_level_name in platform_privilege_levels\n    }\n\n    # this is a list of all possible prompts -- because we are going to use send and expect we\n    # need to be able to expect any prompt OR the paging pattern... so after open and we collect\n    # the prompts for each priv level, we can build this list\n    self.all_expected_patterns = [self.paging_indicator]\n\n    self._determine_privilege_inputs()\n</code></pre>"},{"location":"reference/server/collector/#server.collector.ScrapliCollector.close","title":"<code>close() -&gt; None</code>","text":"<p>Close the Collector and the underlying scrapli connection</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>server/collector.py</code> <pre><code>def close(self) -&gt; None:\n\"\"\"\n    Close the Collector and the underlying scrapli connection\n\n    Args:\n        N/A\n\n    Returns:\n        None\n\n    Raises:\n        None\n\n    \"\"\"\n    self.scrapli_connection.close()\n</code></pre>"},{"location":"reference/server/collector/#server.collector.ScrapliCollector.collect","title":"<code>collect() -&gt; None</code>","text":"<p>Primary public collection method</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>server/collector.py</code> <pre><code>def collect(self) -&gt; None:\n\"\"\"\n    Primary public collection method\n\n    Args:\n        N/A\n\n    Returns:\n        None\n\n    Raises:\n        None\n\n    \"\"\"\n    self._collect_privilege_prompts()\n    self._extend_all_expected_prompts()\n\n    self._collect_priv_and_open_close()\n\n    if isinstance(self.scrapli_connection, EOSDriver):\n        # arista will leave paging enabled even after you exit a connection... kinda throws\n        # things off! so we'll put it back... hate having one off things like this but not sure\n        # there is another easy fix\n        self.scrapli_connection.send_command(command=\"no terminal length\")\n\n    self._collect()\n\n    # close the connection, and reassign the \"normal\" on open so we can capture everything\n    # with \"on_open\" things done (paging disabled and whatever else)\n    self.close()\n    self.scrapli_connection.on_open = self.scrapli_connection_standard_on_open\n    self.scrapli_connection.on_close = self.scrapli_connection_standard_on_close\n    self.open()\n    self.on_open_enabled = True\n\n    self._collect_priv_and_open_close()\n    self._collect()\n</code></pre>"},{"location":"reference/server/collector/#server.collector.ScrapliCollector.dump","title":"<code>dump() -&gt; None</code>","text":"<p>Primary public dump method to dump collected data out to yaml</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>server/collector.py</code> <pre><code>def dump(self) -&gt; None:\n\"\"\"\n    Primary public dump method to dump collected data out to yaml\n\n    Args:\n        N/A\n\n    Returns:\n        None\n\n    Raises:\n        None\n\n    \"\"\"\n    self._serialize()\n\n    logger.debug(\"dumping collected inputs to yaml\")\n\n    dumpable_dict: Dict[str, Any] = {}\n    dumpable_dict[\"events\"] = self.dumpable_events\n    dumpable_dict[\"unknown_events\"] = self.dumpable_unknown_events\n    dumpable_dict[\"initial_privilege_level\"] = self.initial_privilege_level\n    dumpable_dict[\"privilege_level_prompts\"] = self.privilege_level_prompts\n    dumpable_dict[\"on_open_inputs\"] = self.on_open_inputs\n\n    with open(self.collector_session_filename, \"w\", encoding=\"utf-8\") as f:\n        yaml = YAML()\n        yaml.indent(mapping=2, sequence=4, offset=2)\n        yaml.dump(dumpable_dict, f)\n</code></pre>"},{"location":"reference/server/collector/#server.collector.ScrapliCollector.open","title":"<code>open() -&gt; None</code>","text":"<p>Open the Collector and the underlying scrapli connection</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>server/collector.py</code> <pre><code>def open(self) -&gt; None:\n\"\"\"\n    Open the Collector and the underlying scrapli connection\n\n    Args:\n        N/A\n\n    Returns:\n        None\n\n    Raises:\n        None\n\n    \"\"\"\n    self.scrapli_connection.open()\n\n    if not self.initial_privilege_level:\n        # only need to fetch this on the initial open, not for subsequent opens when we need\n        # to reconnect!\n        logger.debug(\n            \"no initial privilege level set, must be first open... setting initial privilege \"\n            \"level\"\n        )\n        self.initial_privilege_level = self._get_current_privilege_level_name()\n</code></pre>"},{"location":"reference/server/server/","title":"Server","text":"<p>scrapli_replay.server.server</p>"},{"location":"reference/server/server/#server.server.BaseSSHServerSession","title":"<code>BaseSSHServerSession</code>","text":"<p>         Bases: <code>SSHServerSession</code></p> Source code in <code>server/server.py</code> <pre><code>class BaseSSHServerSession(SSHServerSession):  # type: ignore\n    def __init__(self, collect_data: Dict[str, Any]) -&gt; None:\n\"\"\"\n        SSH Server Session class\n\n        Inherits from asyncssh and provides some extra context/setup for the mock network devices\n\n        Args:\n            collect_data: dictionary of the collected data necessary to run a mock server\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        logger.debug(\"ssh session initiated\")\n\n        self._chan: SSHServerChannel[Any]\n\n        self._hide_input = False\n        self._interacting = False\n        self._interacting_event: Optional[Dict[str, Any]] = None\n        self._interact_index = 0\n        self._on_open_state = OnOpenState.PRE\n\n        self.collect_data = collect_data\n\n        self._on_open_commands_list = self.collect_data[\"on_open_inputs\"].copy()\n        self.current_privilege_level = self.collect_data[\"initial_privilege_level\"]\n\n    def connection_made(self, chan: SSHServerChannel[Any]) -&gt; None:\n\"\"\"\n        SSH Connection made!\n\n        Args:\n            chan: channel editor object\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        self._chan = chan\n\n    def shell_requested(self) -&gt; bool:\n\"\"\"\n        Handle shell requested; always return True\n\n        Args:\n            N/A\n\n        Returns:\n            bool: always True!\n\n        Raises:\n            N/A\n\n        \"\"\"\n        return True\n\n    def _return_current_prompt(self) -&gt; str:\n\"\"\"\n        Return the current privilege level prompt\n\n        Args:\n            N/A\n\n        Returns:\n            str: prompt for current privilege level\n\n        Raises:\n            N/A\n\n        \"\"\"\n        privilege_level: str = self.collect_data[\"privilege_level_prompts\"][\n            self.current_privilege_level\n        ]\n        return privilege_level\n\n    def session_started(self) -&gt; None:\n\"\"\"\n        SSH session started\n\n        Initial SSH session started\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        self.repaint_prompt()\n\n    def repaint_prompt(self) -&gt; None:\n\"\"\"\n        Paint the prompt to the ssh channel\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        logger.debug(\"writing device prompt\")\n        self._chan.write(self._return_current_prompt())\n\n    def interactive_event(self, channel_input: str) -&gt; None:\n\"\"\"\n        Handle \"interactive\" channel input\n\n        Args:\n            channel_input: input sent from the user on the channel\n\n        Returns:\n            None\n\n        Raises:\n            ScrapliReplayServerError: if we get None for self._interacting_data\n\n        \"\"\"\n        if not self._interacting_event:\n            raise ScrapliReplayServerError(\n                \"attempting to handle interactive event but not in interacting mode. this should\"\n                \" never happen, definitely a bug\"\n            )\n\n        if self._hide_input:\n            # un hide input!\n            logger.debug(\"re-enabling channel echo\")\n            self._chan.set_echo(echo=True)  # type: ignore\n            self._hide_input = False\n\n        event_step = self._interacting_event[\"event_steps\"][self._interact_index]\n\n        if event_step[\"hidden_input\"]:\n            if channel_input != \"scrapli\":\n                # if we have bad auth, basically we'll get stuck here forever... way easier than\n                # trying to model/record all the different device types auth failures i think...\n                logger.warning(\"interactive event input is 'hidden' but input is not 'scrapli'\")\n                self._interact_index -= 1\n                event_step = self._interacting_event[\"event_steps\"][self._interact_index]\n        elif channel_input != event_step[\"channel_input\"]:\n            # bail out and send an invalid input message for the current priv level\n            logger.warning(\"interactive event input does not match recorded event\")\n            self._interacting = False\n            self._interacting_event = None\n            self._interact_index = 0\n            self.unknown_event()\n            return\n\n        self._chan.write(event_step[\"channel_output\"])\n\n        if self._interact_index + 1 == len(self._interacting_event[\"event_steps\"]):\n            # this is the last step, reset all the things\n            logger.debug(\"interactive event complete, resetting interacting mode\")\n            self.current_privilege_level = self._interacting_event[\"result_privilege_level\"]\n            self._interacting = False\n            self._interacting_event = None\n            self._interact_index = 0\n            return\n\n        self._interact_index += 1\n\n        if self._interacting_event[\"event_steps\"][self._interact_index][\"hidden_input\"]:\n            # next event is \"hidden\"... so... hide it...\n            logger.debug(\"next interact event has hidden input, disabling channel echo\")\n            self._chan.set_echo(echo=False)  # type: ignore\n            self._hide_input = True\n\n    def standard_event(self, channel_input: str, event: Dict[str, Any]) -&gt; None:\n\"\"\"\n        Handle \"normal\" command channel input\n\n        Args:\n            channel_input: input sent from the user on the channel\n            event: the event data for the given input\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        # i think if one of these is true both should always be... but just in case...\n        if event[\"channel_output\"] == \"__CLOSES_CONNECTION__\" or event[\"closes_connection\"] is True:\n            logger.debug(\"channel input should close connection, closing...\")\n            # write empty string to bump the connection closed message to a new line like a normal\n            # device\n            self._chan.write(\"\")\n            self.eof_received()\n            # reset privilege level and on open state\n            self.current_privilege_level = self.collect_data[\"initial_privilege_level\"]\n            self._on_open_state = OnOpenState.PRE\n            self._on_open_commands_list = self.collect_data[\"on_open_inputs\"].copy()\n            return\n\n        self._chan.write(event[\"channel_output\"])\n        self.current_privilege_level = event[\"result_privilege_level\"]\n\n        # try to decide if on open things are \"done\"\n        if channel_input in self._on_open_commands_list:\n            logger.debug(\"an 'on open' command was received, popping from on open commands list\")\n            self._on_open_commands_list.pop(self._on_open_commands_list.index(channel_input))\n\n        if not self._on_open_commands_list:\n            logger.debug(\"an 'on open' commands all executed, setting on open state to 'POST'\")\n            self._on_open_state = OnOpenState.POST\n\n    def unknown_event(self) -&gt; None:\n\"\"\"\n        Handle unknown channel input\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        logger.debug(\"an unknown event has been initiated\")\n\n        event = self.collect_data[\"unknown_events\"][self.current_privilege_level][\n            self._on_open_state.value\n        ]\n        self._chan.write(event[\"channel_output\"])\n        if event[\"closes_connection\"] is True:\n            logger.debug(\"channel input should close connection, closing...\")\n            self.eof_received()\n        self.current_privilege_level = event[\"result_privilege_level\"]\n\n    def data_received(self, data: str, datatype: Optional[int]) -&gt; None:\n\"\"\"\n        Handle data received on ssh channel\n\n        Args:\n            data: string of data sent to channel\n            datatype: dunno! in base class though :)\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        _ = datatype\n        # in the future we can cutoff the inputs if it is over X width if disable width has not yet\n        # been ran -- not needed now but could be cool; if we just send a return, we should NOT\n        # strip that!\n        channel_input = data if data == \"\\n\" else data.rstrip()\n\n        logger.debug(f\"received channel input: '{channel_input}'\")\n\n        if self._interacting:\n            logger.debug(\"already in interacting mode, continuing with interact events\")\n            self.interactive_event(channel_input=channel_input)\n            return\n\n        if channel_input == \"\\n\":\n            logger.debug(\"channel input was return, just repaint prompt\")\n            self.repaint_prompt()\n            return\n\n        current_event = self.collect_data[\"events\"][self.current_privilege_level][\n            self._on_open_state.value\n        ].get(channel_input)\n\n        if current_event:\n            if current_event[\"type\"] == \"standard\":\n                logger.debug(\"standard channel event\")\n                self.standard_event(channel_input=channel_input, event=current_event)\n            else:\n                logger.debug(\"interactive channel event\")\n                # set to interacting mode, assign the current interactive event\n                self._interacting = True\n                self._interacting_event = current_event\n                self.interactive_event(channel_input=channel_input)\n            return\n\n        logger.debug(\"unknown channel event\")\n        self.unknown_event()\n\n    def eof_received(self) -&gt; bool:\n\"\"\"\n        Handle eof\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        self._chan.exit(0)\n        return True\n\n    def break_received(self, msec: float) -&gt; bool:\n\"\"\"\n        Handle break\n\n        Args:\n            msec: dunno, but in base class implementation :)\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        self.eof_received()\n        return True\n</code></pre>"},{"location":"reference/server/server/#server.server.BaseSSHServerSession.__init__","title":"<code>__init__(collect_data: Dict[str, Any]) -&gt; None</code>","text":"<p>SSH Server Session class</p> <p>Inherits from asyncssh and provides some extra context/setup for the mock network devices</p> <p>Parameters:</p> Name Type Description Default <code>collect_data</code> <code>Dict[str, Any]</code> <p>dictionary of the collected data necessary to run a mock server</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>server/server.py</code> <pre><code>def __init__(self, collect_data: Dict[str, Any]) -&gt; None:\n\"\"\"\n    SSH Server Session class\n\n    Inherits from asyncssh and provides some extra context/setup for the mock network devices\n\n    Args:\n        collect_data: dictionary of the collected data necessary to run a mock server\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    logger.debug(\"ssh session initiated\")\n\n    self._chan: SSHServerChannel[Any]\n\n    self._hide_input = False\n    self._interacting = False\n    self._interacting_event: Optional[Dict[str, Any]] = None\n    self._interact_index = 0\n    self._on_open_state = OnOpenState.PRE\n\n    self.collect_data = collect_data\n\n    self._on_open_commands_list = self.collect_data[\"on_open_inputs\"].copy()\n    self.current_privilege_level = self.collect_data[\"initial_privilege_level\"]\n</code></pre>"},{"location":"reference/server/server/#server.server.BaseSSHServerSession.break_received","title":"<code>break_received(msec: float) -&gt; bool</code>","text":"<p>Handle break</p> <p>Parameters:</p> Name Type Description Default <code>msec</code> <code>float</code> <p>dunno, but in base class implementation :)</p> required <p>Returns:</p> Type Description <code>bool</code> <p>None</p> Source code in <code>server/server.py</code> <pre><code>def break_received(self, msec: float) -&gt; bool:\n\"\"\"\n    Handle break\n\n    Args:\n        msec: dunno, but in base class implementation :)\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    self.eof_received()\n    return True\n</code></pre>"},{"location":"reference/server/server/#server.server.BaseSSHServerSession.connection_made","title":"<code>connection_made(chan: SSHServerChannel[Any]) -&gt; None</code>","text":"<p>SSH Connection made!</p> <p>Parameters:</p> Name Type Description Default <code>chan</code> <code>SSHServerChannel[Any]</code> <p>channel editor object</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>server/server.py</code> <pre><code>def connection_made(self, chan: SSHServerChannel[Any]) -&gt; None:\n\"\"\"\n    SSH Connection made!\n\n    Args:\n        chan: channel editor object\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    self._chan = chan\n</code></pre>"},{"location":"reference/server/server/#server.server.BaseSSHServerSession.data_received","title":"<code>data_received(data: str, datatype: Optional[int]) -&gt; None</code>","text":"<p>Handle data received on ssh channel</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>str</code> <p>string of data sent to channel</p> required <code>datatype</code> <code>Optional[int]</code> <p>dunno! in base class though :)</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>server/server.py</code> <pre><code>def data_received(self, data: str, datatype: Optional[int]) -&gt; None:\n\"\"\"\n    Handle data received on ssh channel\n\n    Args:\n        data: string of data sent to channel\n        datatype: dunno! in base class though :)\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    _ = datatype\n    # in the future we can cutoff the inputs if it is over X width if disable width has not yet\n    # been ran -- not needed now but could be cool; if we just send a return, we should NOT\n    # strip that!\n    channel_input = data if data == \"\\n\" else data.rstrip()\n\n    logger.debug(f\"received channel input: '{channel_input}'\")\n\n    if self._interacting:\n        logger.debug(\"already in interacting mode, continuing with interact events\")\n        self.interactive_event(channel_input=channel_input)\n        return\n\n    if channel_input == \"\\n\":\n        logger.debug(\"channel input was return, just repaint prompt\")\n        self.repaint_prompt()\n        return\n\n    current_event = self.collect_data[\"events\"][self.current_privilege_level][\n        self._on_open_state.value\n    ].get(channel_input)\n\n    if current_event:\n        if current_event[\"type\"] == \"standard\":\n            logger.debug(\"standard channel event\")\n            self.standard_event(channel_input=channel_input, event=current_event)\n        else:\n            logger.debug(\"interactive channel event\")\n            # set to interacting mode, assign the current interactive event\n            self._interacting = True\n            self._interacting_event = current_event\n            self.interactive_event(channel_input=channel_input)\n        return\n\n    logger.debug(\"unknown channel event\")\n    self.unknown_event()\n</code></pre>"},{"location":"reference/server/server/#server.server.BaseSSHServerSession.eof_received","title":"<code>eof_received() -&gt; bool</code>","text":"<p>Handle eof</p> <p>Returns:</p> Type Description <code>bool</code> <p>None</p> Source code in <code>server/server.py</code> <pre><code>def eof_received(self) -&gt; bool:\n\"\"\"\n    Handle eof\n\n    Args:\n        N/A\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    self._chan.exit(0)\n    return True\n</code></pre>"},{"location":"reference/server/server/#server.server.BaseSSHServerSession.interactive_event","title":"<code>interactive_event(channel_input: str) -&gt; None</code>","text":"<p>Handle \"interactive\" channel input</p> <p>Parameters:</p> Name Type Description Default <code>channel_input</code> <code>str</code> <p>input sent from the user on the channel</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>ScrapliReplayServerError</code> <p>if we get None for self._interacting_data</p> Source code in <code>server/server.py</code> <pre><code>def interactive_event(self, channel_input: str) -&gt; None:\n\"\"\"\n    Handle \"interactive\" channel input\n\n    Args:\n        channel_input: input sent from the user on the channel\n\n    Returns:\n        None\n\n    Raises:\n        ScrapliReplayServerError: if we get None for self._interacting_data\n\n    \"\"\"\n    if not self._interacting_event:\n        raise ScrapliReplayServerError(\n            \"attempting to handle interactive event but not in interacting mode. this should\"\n            \" never happen, definitely a bug\"\n        )\n\n    if self._hide_input:\n        # un hide input!\n        logger.debug(\"re-enabling channel echo\")\n        self._chan.set_echo(echo=True)  # type: ignore\n        self._hide_input = False\n\n    event_step = self._interacting_event[\"event_steps\"][self._interact_index]\n\n    if event_step[\"hidden_input\"]:\n        if channel_input != \"scrapli\":\n            # if we have bad auth, basically we'll get stuck here forever... way easier than\n            # trying to model/record all the different device types auth failures i think...\n            logger.warning(\"interactive event input is 'hidden' but input is not 'scrapli'\")\n            self._interact_index -= 1\n            event_step = self._interacting_event[\"event_steps\"][self._interact_index]\n    elif channel_input != event_step[\"channel_input\"]:\n        # bail out and send an invalid input message for the current priv level\n        logger.warning(\"interactive event input does not match recorded event\")\n        self._interacting = False\n        self._interacting_event = None\n        self._interact_index = 0\n        self.unknown_event()\n        return\n\n    self._chan.write(event_step[\"channel_output\"])\n\n    if self._interact_index + 1 == len(self._interacting_event[\"event_steps\"]):\n        # this is the last step, reset all the things\n        logger.debug(\"interactive event complete, resetting interacting mode\")\n        self.current_privilege_level = self._interacting_event[\"result_privilege_level\"]\n        self._interacting = False\n        self._interacting_event = None\n        self._interact_index = 0\n        return\n\n    self._interact_index += 1\n\n    if self._interacting_event[\"event_steps\"][self._interact_index][\"hidden_input\"]:\n        # next event is \"hidden\"... so... hide it...\n        logger.debug(\"next interact event has hidden input, disabling channel echo\")\n        self._chan.set_echo(echo=False)  # type: ignore\n        self._hide_input = True\n</code></pre>"},{"location":"reference/server/server/#server.server.BaseSSHServerSession.repaint_prompt","title":"<code>repaint_prompt() -&gt; None</code>","text":"<p>Paint the prompt to the ssh channel</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>server/server.py</code> <pre><code>def repaint_prompt(self) -&gt; None:\n\"\"\"\n    Paint the prompt to the ssh channel\n\n    Args:\n        N/A\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    logger.debug(\"writing device prompt\")\n    self._chan.write(self._return_current_prompt())\n</code></pre>"},{"location":"reference/server/server/#server.server.BaseSSHServerSession.session_started","title":"<code>session_started() -&gt; None</code>","text":"<p>SSH session started</p> <p>Initial SSH session started</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>server/server.py</code> <pre><code>def session_started(self) -&gt; None:\n\"\"\"\n    SSH session started\n\n    Initial SSH session started\n\n    Args:\n        N/A\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    self.repaint_prompt()\n</code></pre>"},{"location":"reference/server/server/#server.server.BaseSSHServerSession.shell_requested","title":"<code>shell_requested() -&gt; bool</code>","text":"<p>Handle shell requested; always return True</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>always True!</p> Source code in <code>server/server.py</code> <pre><code>def shell_requested(self) -&gt; bool:\n\"\"\"\n    Handle shell requested; always return True\n\n    Args:\n        N/A\n\n    Returns:\n        bool: always True!\n\n    Raises:\n        N/A\n\n    \"\"\"\n    return True\n</code></pre>"},{"location":"reference/server/server/#server.server.BaseSSHServerSession.standard_event","title":"<code>standard_event(channel_input: str, event: Dict[str, Any]) -&gt; None</code>","text":"<p>Handle \"normal\" command channel input</p> <p>Parameters:</p> Name Type Description Default <code>channel_input</code> <code>str</code> <p>input sent from the user on the channel</p> required <code>event</code> <code>Dict[str, Any]</code> <p>the event data for the given input</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>server/server.py</code> <pre><code>def standard_event(self, channel_input: str, event: Dict[str, Any]) -&gt; None:\n\"\"\"\n    Handle \"normal\" command channel input\n\n    Args:\n        channel_input: input sent from the user on the channel\n        event: the event data for the given input\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    # i think if one of these is true both should always be... but just in case...\n    if event[\"channel_output\"] == \"__CLOSES_CONNECTION__\" or event[\"closes_connection\"] is True:\n        logger.debug(\"channel input should close connection, closing...\")\n        # write empty string to bump the connection closed message to a new line like a normal\n        # device\n        self._chan.write(\"\")\n        self.eof_received()\n        # reset privilege level and on open state\n        self.current_privilege_level = self.collect_data[\"initial_privilege_level\"]\n        self._on_open_state = OnOpenState.PRE\n        self._on_open_commands_list = self.collect_data[\"on_open_inputs\"].copy()\n        return\n\n    self._chan.write(event[\"channel_output\"])\n    self.current_privilege_level = event[\"result_privilege_level\"]\n\n    # try to decide if on open things are \"done\"\n    if channel_input in self._on_open_commands_list:\n        logger.debug(\"an 'on open' command was received, popping from on open commands list\")\n        self._on_open_commands_list.pop(self._on_open_commands_list.index(channel_input))\n\n    if not self._on_open_commands_list:\n        logger.debug(\"an 'on open' commands all executed, setting on open state to 'POST'\")\n        self._on_open_state = OnOpenState.POST\n</code></pre>"},{"location":"reference/server/server/#server.server.BaseSSHServerSession.unknown_event","title":"<code>unknown_event() -&gt; None</code>","text":"<p>Handle unknown channel input</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>server/server.py</code> <pre><code>def unknown_event(self) -&gt; None:\n\"\"\"\n    Handle unknown channel input\n\n    Args:\n        N/A\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    logger.debug(\"an unknown event has been initiated\")\n\n    event = self.collect_data[\"unknown_events\"][self.current_privilege_level][\n        self._on_open_state.value\n    ]\n    self._chan.write(event[\"channel_output\"])\n    if event[\"closes_connection\"] is True:\n        logger.debug(\"channel input should close connection, closing...\")\n        self.eof_received()\n    self.current_privilege_level = event[\"result_privilege_level\"]\n</code></pre>"},{"location":"reference/server/server/#server.server.BaseServer","title":"<code>BaseServer</code>","text":"<p>         Bases: <code>SSHServer</code></p> Source code in <code>server/server.py</code> <pre><code>class BaseServer(SSHServer):\n    def __init__(self, session: Type[SSHServerSession], collect_data: str):  # type: ignore\n\"\"\"\n        Base Server class\n\n        Args:\n            session: asyncssh server session\n            collect_data: yaml of session to load\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        self.session = session\n\n        with open(collect_data, \"r\", encoding=\"utf-8\") as f:\n            self.collect_data = YAML.load(f)\n\n    def session_requested(self) -&gt; SSHServerSession:  # type: ignore\n\"\"\"\n        Session requested; return ServerSession object\n\n        `ServerSession` set in `run` to be the appropriate SSHServerSession type for a given\n        platform, i.e. `IOSXESSHServerSession`\n\n        Args:\n            N/A\n\n        Returns:\n            SSHServerSession: SSHServerSession\n\n        Raises:\n            N/A\n\n        \"\"\"\n        return self.session(collect_data=self.collect_data)  # type: ignore\n\n    def begin_auth(self, username: str) -&gt; bool:\n\"\"\"\n        Begin auth; always returns True\n\n        Args:\n            username: username for auth\n\n        Returns:\n            bool: always True\n\n        Raises:\n            N/A\n\n        \"\"\"\n        return True\n\n    def password_auth_supported(self) -&gt; bool:\n\"\"\"\n        Password auth supported; always return True\n\n        Args:\n            N/A\n\n        Returns:\n            bool: always True\n\n        Raises:\n            N/A\n\n        \"\"\"\n        return True\n\n    def public_key_auth_supported(self) -&gt; bool:\n\"\"\"\n        Public key auth supported; always return True\n\n        Args:\n            N/A\n\n        Returns:\n            bool: always True\n\n        Raises:\n            N/A\n\n        \"\"\"\n        return True\n\n    def validate_password(self, username: str, password: str) -&gt; bool:\n\"\"\"\n        Validate provided username/password\n\n        Args:\n            username: username to check for auth\n            password: password to check for auth\n\n        Returns:\n            bool: True if user/password is correct (scrapli/scrapli)\n\n        Raises:\n            N/A\n\n        \"\"\"\n        if username == password == \"scrapli\":\n            return True\n        return False\n\n    def validate_public_key(self, username: str, key: SSHKey) -&gt; bool:\n\"\"\"\n        Validate provided public key\n\n        Args:\n            username: username to check for auth\n            key: asyncssh RSAKey to check for auth\n\n        Returns:\n            bool: True if ssh key is correct\n\n        Raises:\n            N/A\n\n        \"\"\"\n        if (\n            username == \"scrapli\"\n            and key.get_fingerprint() == \"SHA256:rb1CVtQCkWBAzm1AxV7xR7BLBawUwFUlUVFVu+QYQBM\"\n        ):\n            return True\n        return False\n</code></pre>"},{"location":"reference/server/server/#server.server.BaseServer.__init__","title":"<code>__init__(session: Type[SSHServerSession], collect_data: str)</code>","text":"<p>Base Server class</p> <p>Parameters:</p> Name Type Description Default <code>session</code> <code>Type[SSHServerSession]</code> <p>asyncssh server session</p> required <code>collect_data</code> <code>str</code> <p>yaml of session to load</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>server/server.py</code> <pre><code>def __init__(self, session: Type[SSHServerSession], collect_data: str):  # type: ignore\n\"\"\"\n    Base Server class\n\n    Args:\n        session: asyncssh server session\n        collect_data: yaml of session to load\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    self.session = session\n\n    with open(collect_data, \"r\", encoding=\"utf-8\") as f:\n        self.collect_data = YAML.load(f)\n</code></pre>"},{"location":"reference/server/server/#server.server.BaseServer.begin_auth","title":"<code>begin_auth(username: str) -&gt; bool</code>","text":"<p>Begin auth; always returns True</p> <p>Parameters:</p> Name Type Description Default <code>username</code> <code>str</code> <p>username for auth</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>always True</p> Source code in <code>server/server.py</code> <pre><code>def begin_auth(self, username: str) -&gt; bool:\n\"\"\"\n    Begin auth; always returns True\n\n    Args:\n        username: username for auth\n\n    Returns:\n        bool: always True\n\n    Raises:\n        N/A\n\n    \"\"\"\n    return True\n</code></pre>"},{"location":"reference/server/server/#server.server.BaseServer.password_auth_supported","title":"<code>password_auth_supported() -&gt; bool</code>","text":"<p>Password auth supported; always return True</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>always True</p> Source code in <code>server/server.py</code> <pre><code>def password_auth_supported(self) -&gt; bool:\n\"\"\"\n    Password auth supported; always return True\n\n    Args:\n        N/A\n\n    Returns:\n        bool: always True\n\n    Raises:\n        N/A\n\n    \"\"\"\n    return True\n</code></pre>"},{"location":"reference/server/server/#server.server.BaseServer.public_key_auth_supported","title":"<code>public_key_auth_supported() -&gt; bool</code>","text":"<p>Public key auth supported; always return True</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>always True</p> Source code in <code>server/server.py</code> <pre><code>def public_key_auth_supported(self) -&gt; bool:\n\"\"\"\n    Public key auth supported; always return True\n\n    Args:\n        N/A\n\n    Returns:\n        bool: always True\n\n    Raises:\n        N/A\n\n    \"\"\"\n    return True\n</code></pre>"},{"location":"reference/server/server/#server.server.BaseServer.session_requested","title":"<code>session_requested() -&gt; SSHServerSession</code>","text":"<p>Session requested; return ServerSession object</p> <p><code>ServerSession</code> set in <code>run</code> to be the appropriate SSHServerSession type for a given platform, i.e. <code>IOSXESSHServerSession</code></p> <p>Returns:</p> Name Type Description <code>SSHServerSession</code> <code>SSHServerSession</code> <p>SSHServerSession</p> Source code in <code>server/server.py</code> <pre><code>def session_requested(self) -&gt; SSHServerSession:  # type: ignore\n\"\"\"\n    Session requested; return ServerSession object\n\n    `ServerSession` set in `run` to be the appropriate SSHServerSession type for a given\n    platform, i.e. `IOSXESSHServerSession`\n\n    Args:\n        N/A\n\n    Returns:\n        SSHServerSession: SSHServerSession\n\n    Raises:\n        N/A\n\n    \"\"\"\n    return self.session(collect_data=self.collect_data)  # type: ignore\n</code></pre>"},{"location":"reference/server/server/#server.server.BaseServer.validate_password","title":"<code>validate_password(username: str, password: str) -&gt; bool</code>","text":"<p>Validate provided username/password</p> <p>Parameters:</p> Name Type Description Default <code>username</code> <code>str</code> <p>username to check for auth</p> required <code>password</code> <code>str</code> <p>password to check for auth</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if user/password is correct (scrapli/scrapli)</p> Source code in <code>server/server.py</code> <pre><code>def validate_password(self, username: str, password: str) -&gt; bool:\n\"\"\"\n    Validate provided username/password\n\n    Args:\n        username: username to check for auth\n        password: password to check for auth\n\n    Returns:\n        bool: True if user/password is correct (scrapli/scrapli)\n\n    Raises:\n        N/A\n\n    \"\"\"\n    if username == password == \"scrapli\":\n        return True\n    return False\n</code></pre>"},{"location":"reference/server/server/#server.server.BaseServer.validate_public_key","title":"<code>validate_public_key(username: str, key: SSHKey) -&gt; bool</code>","text":"<p>Validate provided public key</p> <p>Parameters:</p> Name Type Description Default <code>username</code> <code>str</code> <p>username to check for auth</p> required <code>key</code> <code>SSHKey</code> <p>asyncssh RSAKey to check for auth</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if ssh key is correct</p> Source code in <code>server/server.py</code> <pre><code>def validate_public_key(self, username: str, key: SSHKey) -&gt; bool:\n\"\"\"\n    Validate provided public key\n\n    Args:\n        username: username to check for auth\n        key: asyncssh RSAKey to check for auth\n\n    Returns:\n        bool: True if ssh key is correct\n\n    Raises:\n        N/A\n\n    \"\"\"\n    if (\n        username == \"scrapli\"\n        and key.get_fingerprint() == \"SHA256:rb1CVtQCkWBAzm1AxV7xR7BLBawUwFUlUVFVu+QYQBM\"\n    ):\n        return True\n    return False\n</code></pre>"},{"location":"reference/server/server/#server.server.start","title":"<code>start(port: int = 2222, collect_data: str = 'scrapli_replay.yaml') -&gt; None</code>  <code>async</code>","text":"<p>Temporary run server entrypoint</p> <p>Parameters:</p> Name Type Description Default <code>port</code> <code>int</code> <p>port to run the instance on</p> <code>2222</code> <code>collect_data</code> <code>str</code> <p>string path/name to collect data yaml file</p> <code>'scrapli_replay.yaml'</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>server/server.py</code> <pre><code>async def start(port: int = 2222, collect_data: str = \"scrapli_replay.yaml\") -&gt; None:\n\"\"\"\n    Temporary run server entrypoint\n\n    Args:\n        port: port to run the instance on\n        collect_data: string path/name to collect data yaml file\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n\n    def server_factory() -&gt; SSHServer:\n        server = BaseServer(session=BaseSSHServerSession, collect_data=collect_data)\n        return server\n\n    await create_server(\n        server_factory,\n        \"localhost\",\n        port,\n        server_host_keys=[BASE_SERVER_KEY],\n    )\n</code></pre>"},{"location":"user_guide/basic_usage/","title":"Basic Usage","text":""},{"location":"user_guide/basic_usage/#what-do-you-need-to-get-done","title":"What do you need to get done!?!","text":"<p>First things first: what do you need to get done? scrapli replay contains two similar yet very different testing  tools. </p> <p>The first, is the pytest plugin -- a plugin to mark tests with. This plugin will record scrapli session  inputs and outputs and save them, that way you can store these test sessions and re-use them (without needing a  \"live\" device) in your CI setup.</p> <p>The second, is a \"collector\", and a \"server\" that allow you to build semi-interactive SSH servers that you can  connect to for testing purposes. This allows you to have \"mock\"/\"fake\"/\"dummy\" SSH server(s) that look and feel like  \"real\" network devices -- as with the pytest plugin, this could be useful in CI, or it could just be handy for  offline testing.</p> <p>As you'd expect, if you are writing tests and wanting to have some reasonable assurances that your code that  interacts with scrapli is doing what you think it should be doing, then you probably want to use the pytest plugin!  If you just want to have a mock SSH server to play with, then the collector/server may be interesting to you.</p>"},{"location":"user_guide/basic_usage/#pytest-plugin","title":"Pytest Plugin","text":""},{"location":"user_guide/basic_usage/#overview-and-use-case","title":"Overview and Use Case","text":"<p>As shown in the quickstart guide, getting going with the pytest plugin is fairly straightforward -- tests that  contain scrapli operations can be marked with the <code>scrapli_replay</code> marker, causing scrapli replay to automatically  wrap this test and record or replay sessions within the test.</p> <p>In order for scrapli replay to do this, there is one big caveat: the scrapli connection must be opened within the  test! Projects like <code>pytest-vcr</code> don't have this requirement because the sessions are stateless HTTP(s) sessions --  this is of course not the case for Telnet/SSH where we have more or less a stateful connection object. This may  sound like a limiting factor for scrapli replay and perhaps it is, however it is relatively easy to work with as  you'll see below!</p> <p>Here is a very simple example of a class that creates a scrapli connection and has some methods to do stuff:</p> <pre><code>import re\nfrom scrapli import Scrapli\n\n\nclass Example:\n    def __init__(self):\n        self.conn = Scrapli(\n            host=\"c3560\", platform=\"cisco_iosxe\", ssh_config_file=True, auth_strict_key=False\n        )\n        # dont do this! dont have side affects in init, but helps demonstrate things!\n        self.conn.open()\n\n    def do_stuff(self):\n\"\"\"Get the version from the device\"\"\"\n        version_result = self.conn.send_command(command=\"show version | i Software\")\n\n        if version_result.failed is True:\n            return \"__FAILURE__\"\n\n        version_result_string = version_result.result\n        version_result_match = re.findall(\n            pattern=r\"Version ([a-z0-9\\.\\(\\)]*)\", string=version_result_string, flags=re.I\n        )\n\n        if not version_result_match:\n            return \"__FAILURE__\"\n\n        return version_result_match[0]\n</code></pre> <p>Let's pretend we want to write some tests for the <code>do_stuff</code> method of this example class. We probably want to have  at least three test cases for this method:</p> <ol> <li>Testing a failed result from the initial show command</li> <li>Testing a success event where we properly get and parse the version string</li> <li>Testing a failed parsing of the version string</li> </ol> <p>For cases one and three we probably don't want or need scrapli replay -- we could simply patch the <code>send_command</code>  method of scrapli, returning bad data -- either a bad scrapli <code>Response</code> object, or a <code>Response</code> object with data  that will cause our regex to fail.</p> <p>For case number 2, however, we could also patch scrapli and return correct data, this would validate that our  function, when given appropriate outputs from scrapli, does what it should do. This would be a valuable test. With  scrapli replay, however, we can take this a bit further! We can now create a test case that records actual device  inputs and outputs and saves that data in a scrapli replay session. Subsequent tests can then replay that input  and output data. Rather than just testing that our regex works w/ some patched response data we can now very simply  test not only that, but also scrapli -- ensuring that scrapli is behaving as you would expect!</p>"},{"location":"user_guide/basic_usage/#how-it-works","title":"How it Works","text":"<p>Before jumping into how to use scrapli replay, it's worth spending a bit of time to understand how it works. At a  high level, scrapli replay is a Pytest plugin that you can \"mark\" tests with. By marking a test you are effectively  \"wrapping\" that test in the scrapli replay <code>ScrapliReplay</code> class.</p> <p>The pytest plugin then uses the <code>ScrapliReplay</code> class as a context manager, yielding to your test within the context  manager. For tests that are marked <code>asyncio</code> we simply use the async context manager capability instead of the  synchronous version. This selection of sync vs async happens transparently to you --  you just need to mark your  tests with the <code>asyncio</code> marker if they are asyncio (which you had to do anyway, so no biggie!).</p> <p>While the <code>ScrapliReplay</code> context manager is active (while your test is running) <code>ScrapliReplay</code> patches the <code>open</code>  method of scrapli and a <code>ConnectionProfile</code> is recorded (host/user/is using password/auth  bypass/etc.). This <code>ConnectionProfile</code> is stored as part of the scrapli replay session data -- allowing us to  validate that during subsequent test runs the connection information has not changed (if it has we raise an  exception to fail the test).</p> <p>After the <code>ConnectionProfile</code> is recorded, the scrapli <code>Channel</code> (or <code>AsyncChannel</code>) read and write methods are  patched (replaced) with scrapli replay read/write methods. If the current test iteration is in \"record\" mode, we  patch with the \"record\" read/write, otherwise we patch with the \"replay\" read/write -- these methods do what they  sound like! Recording or replaying session data.</p> <p>At completion of your test, when the context manager is closing the session will be dumped to a yaml file in your  session output directory (by default this is a folder located with your test file).</p> <p>Due to the fact that scrapli replay uses the open method of scrapli in order to fetch connection data and also to  patch the channel objects, there is a requirement that the test actually opens the connection. This sounds perhaps  limiting, and probably it is somewhat, however you can fairly easily work around this by having a fixture that  returns an object with the connection already opened -- this fixture currently must be scoped to the function  level. This will hopefully be improved in further scrapli replay releases to allow us to cache session-wide fixtures.</p>"},{"location":"user_guide/basic_usage/#how-to-use-it","title":"How to Use it","text":"<p>As shown in the quickstart, using scrapli replay is fairly straightforward -- simply mark a test with the correct  marker. The complication generally will come from needing to have the connection opened within that test being  wrapped -- this section will showcase some basic ways to use scrapli replay, as well as how we can handle the  connection opening problem.</p> <p>Working with the example class from the overview section, let's handle test case number 2. To start, we can do this  with the patching method -- without scrapli replay:</p> <pre><code>from scrapli.response import Response\n\n\ndef test_example_do_stuff_patching(monkeypatch, example_instance):\n\"\"\"Test Example.do_stuff\"\"\"\n    def patched_send_command(cls, command):\n        r = Response(host=\"localhost\", channel_input=command)\n        r.record_response(b\"Software Version 15.2(4)E7\")\n        return r\n\n    monkeypatch.setattr(\"scrapli.driver.network.sync_driver.NetworkDriver.send_command\", patched_send_command)\n    assert example_instance.do_stuff() == \"15.2(4)E7\"\n</code></pre> <p>This works reasonably well, and properly tests our regex does indeed find the version string; of course you could  actually return a real device output instead of the abbreviated output here as well -- that would make things a bit  more \"real\". This is nice, but it does not test any scrapli behavior at all as scrapli is completely patched out of  the test. There must be a better way!</p> <p>Let's now re-write this test using scrapli replay:</p> <pre><code>import pytest\nfrom example import Example  # &lt;- this is assuming directory structure as in the \"examples/simple_test_case\" example!\n\n@pytest.mark.scrapli_replay\ndef test_example_do_stuff_no_fixture():\n\"\"\"Test Example.do_stuff\"\"\"\n    assert Example().do_stuff() == \"15.2(4)E7\"\n</code></pre> <p>No patching?! Amazing! So... what is going on here?</p> <p>The <code>Example</code> class (from the snippet way above here) is created, which causes the scrapli connection to open, then  we call the <code>do_stuff</code> method which fetches the version and parses it with some regex. Scrapli replay is \"aware\" of  this test due to the marker -- this basically means that this test is living inside of a scrapli replay context  manager... you can think of it as something like this:</p> <pre><code>with ScrapliReplay:\n    test()\n</code></pre> <p>An oversimplified example, but not by much!</p> <p>If you run this example (from the examples dir in the repo) the first time the test is ran, scrapli will actually  connect to your device and record the output. This of course means that you need proper credentials/access in order  to get this first recording done -- using ssh keys/config file so that you don't need to store any user/creds in  your test is a great way to deal with this.</p> <p>At the end of the test, scrapli replay will dump the \"session\" data out to a yaml file in a new folder called  \"scrapli_replay_sessions\" that was created in the same directory of your test file (you can change this, see the  options section!). This \"session\" file looks like this:</p> <pre><code>connection_profile:\nhost: c3560\nport: 22\nauth_username: ''\nauth_password: false\nauth_private_key: ''\nauth_private_key_passphrase: false\nauth_bypass: false\ntransport: system\nauth_secondary: false\ninteractions:\n- channel_output: \"Warning: Permanently added 'c3560,172.31.254.1' (RSA) to the\\\n\\ list of known hosts.\\n\\nC3560CX#\"\nexpected_channel_input: \"\\n\"\nexpected_channel_input_redacted: false\n- channel_output: \"\\nC3560CX#\"\nexpected_channel_input: terminal length 0\nexpected_channel_input_redacted: false\n- channel_output: terminal length 0\nexpected_channel_input: \"\\n\"\nexpected_channel_input_redacted: false\n- channel_output: \"\\nC3560CX#\"\nexpected_channel_input: terminal width 512\nexpected_channel_input_redacted: false\n- channel_output: terminal width 512\nexpected_channel_input: \"\\n\"\nexpected_channel_input_redacted: false\n- channel_output: \"\\nC3560CX#\"\nexpected_channel_input: show version | i Software\nexpected_channel_input_redacted: false\n- channel_output: show version | i Software\nexpected_channel_input: \"\\n\"\nexpected_channel_input_redacted: false\n- channel_output: \"\\nCisco IOS Software, C3560CX Software (C3560CX-UNIVERSALK9-M),\\\n\\ Version 15.2(4)E7, RELEASE SOFTWARE (fc2)\\nC3560CX#\"\nexpected_channel_input:\nexpected_channel_input_redacted: false\n</code></pre> <p>As you can see, connection details are stored (but never credentials) -- in the event of password authentication the  password is not stored and is marked as \"REDACTED\" in the interactions output.</p> <p>Running the test again you'll notice that its even faster than scrapli normally is! Why? Because there is no actual  connection going out to the device, the connection will just be automatically replayed from this session data!</p> <p>Now if you have a billion tests to write, or you are needing to pass lots of inputs in order to create your scrapli  connection objects in every single test... that wouldn't be very fun! In cases like this it would be a great idea to  put either the scrapli connection object, or the device containing the connection object into a fixture and allowing  pytest to pass that fixture into each test function. Here is a simple example of a fixture for our example setup:</p> <pre><code>import pytest\nfrom example import Example\n\n\n@pytest.fixture(scope=\"function\")\ndef example_instance():\n\"\"\"Simple fixture to return Example instance\"\"\"\n    yield Example()\n</code></pre> <p>And... a test taking advantage of this fixture:</p> <pre><code>@pytest.mark.scrapli_replay\ndef test_example_do_stuff_with_fixture(example_instance):\n\"\"\"Test Example.do_stuff\"\"\"\n    assert example_instance.do_stuff() == \"15.2(4)E7\"\n</code></pre> <p>It is important to note that the fixture scope must be set to <code>function</code> -- again, this is because scrapli replay  requires the connection to be opened within the test it is wrapping in order to properly record the connection  profile and patch the read/write methods!</p>"},{"location":"user_guide/basic_usage/#pytest-plugin-options","title":"Pytest Plugin Options","text":"<p>scrapli replay supports a handful of arguments to modify its behavior, currently, these are configurable via the  pytest cli -- in the future they will likely be configurable by a dedicated fixture as well.</p> <p>The available options are:</p>"},{"location":"user_guide/basic_usage/#mode","title":"Mode","text":"<p>The \"replay\" mode setting manages how scrapli replay handles replaying or recording sessions. This setting has the  following options:</p> <ul> <li>replay: the default mode; if no session exists scrapli replay will record/create one, otherwise it will \"replay\"    existing sessions (meaning you dont need to connect to a device)</li> <li>record: probably not needed often, does at it says -- records things. If a session exists it will auto switch to    replay mode (meaning not overwrite the session)</li> <li>overwrite: overwrite existing all sessions always</li> </ul> <p>This option is configurable with the <code>--scrapli-replay-mode</code> switch:</p> <pre><code>python -m pytest tests --scrapli-replay-mode overwrite\n</code></pre>"},{"location":"user_guide/basic_usage/#directory","title":"Directory","text":"<p>By default, scrapli replay stores the recorded sessions in a directory in the same folder as the test that is being  executed. This is modifiable with the <code>--scrapli-replay-directory</code> switch:</p> <pre><code>python -m pytest tests --scrapli-replay-directory /my/cool/session/dir\n</code></pre>"},{"location":"user_guide/basic_usage/#overwrite","title":"Overwrite","text":"<p>If you need to overwrite only certain test session data, you can do so by using the <code>--scrapli-replay-overwrite</code>  switch. This argument accepts a comma separated list of test names of which to overwrite the session data.</p> <pre><code>python -m pytest tests --scrapli-replay-overwrite test1,test2,test3\n</code></pre>"},{"location":"user_guide/basic_usage/#disable","title":"Disable","text":"<p>You can disable entirely the scrapli replay functionality -- meaning your tests will run \"normally\" without  any of the scrapli replay patching/session work happening. This is done with the <code>--scrapli-replay-disable</code> flag.</p> <pre><code>python -m pytest tests --scrapli-replay-disable\n</code></pre>"},{"location":"user_guide/basic_usage/#block-network","title":"Block Network","text":"<p>Finally, you can \"block\" network connections -- this will cause any connection with a valid recorded session to be  \"replay\"'d as normal, but any tests that would require recording a session will be skipped. The  <code>--scrapli-replay-block-network</code> flag controls this.</p> <pre><code>python -m pytest tests --scrapli-replay-block-network\n</code></pre>"},{"location":"user_guide/basic_usage/#collector-and-server","title":"Collector and Server","text":""},{"location":"user_guide/basic_usage/#overview","title":"Overview","text":"<p>The scrapli replay \"collector\" and \"server\" functionality is useful for creating mock ssh servers that are  \"semi-interactive\". You can provide any number of commands (not configs! more on this in a bit) that you would like  to collect from a device, and the collector will run the provided commands at all privilege levels, and with and  without \"on_open\" functionality being executed (generally this means with and without paging being disabled). The  collector will also collect any on open commands, on close commands, all privilege escalation/deescalation commands,  and \"unknown\" or invalid command output from every privilege level. </p> <p>Just like the pytest plugin, the scrapli replay collector will output the collected data to a yaml file. This yaml  file is then consumed by the scrapli replay server. The server itself is an asyncssh server that does its best to  look and feel just like the real device that you collected the data from.</p>"},{"location":"user_guide/basic_usage/#collector","title":"Collector","text":"<p>As outlined in the overview section, the collector.... collects things! The collector tries to collect as much info  from the device as is practical, with the ultimate goal of being able to allow the server to look pretty close to a  real device.</p> <p>Before continuing, it is important to note that currently the collector can only be used with network devices --  meaning it must be used with a scrapli platform that extends the <code>NetworkDriver</code> class; moreover it must be used  with a synchronous transport. There will likely not be any asyncio support for the collector (it doesn't seem to  be very valuable to add asyncio support...  please open an issue if you disagree!).</p> <p>To get started with the collector is fairly straight forward, simply create a collector class, passing in the  commands you wish to collect, some details about \"paging\" (more on this in a sec), and the kwargs necessary to create  the scrapli connection to collect from:</p> <pre><code>from scrapli_replay.server.collector import ScrapliCollector\n\nscrapli_kwargs = {\n    \"host\": \"localhost\",\n    \"port\": 24022,\n    \"ssh_config_file\": False,\n    \"auth_strict_key\": False,\n    \"auth_username\": \"vrnetlab\",\n    \"auth_password\": \"VR-netlab9\",\n    \"auth_secondary\": \"VR-netlab9\",\n    \"platform\": \"arista_eos\",\n}\n\ncollector = ScrapliCollector(\n    channel_inputs=[\"show version\", \"show run\"],\n    interact_events=[\n        [(\"clear logg\", \"Clear logging buffer [confirm]\", False), (\"\", \"switch#\", False)]\n    ],\n    paging_indicator=\"--More--\",\n    paging_escape_string=\"\\x1b\",\n    **scrapli_kwargs,\n)\n</code></pre> <p>If you are familiar with scrapli connections, the above snippet should look fairly similar! In addition to the  scrapli connection data we see a few extra things:</p> <ul> <li><code>channel_inputs</code> -- a list of \"inputs\" you wish to send to the device for recording. Each of these inputs will be    run at every privilege level of the device, and before and after executing the \"on_open\" function (if applicable)</li> <li><code>interact_events</code> -- similar to \"normal\" scrapli, a list of lists of tuples of \"interact events\" to record at each    privilege level (and before/after on_open)</li> <li><code>paging_indicator</code> -- this is what it sounds like -- a string that lets us know if the device has paginated output    data</li> <li><code>paging_escape_string</code> -- a string to send to \"cancel\" a command output if paging is encountered -- typically an    escape, or a <code>q</code> works for most devices</li> </ul> <p>Note -- you can also pass an existing scrapli connection to the <code>scrapli_connection</code> argument if you prefer  (instead of the kwargs needed to create a connection)!</p> <p>Once a collector object has been created, you can open the connection and simply run the <code>collect</code> method, followed  by the <code>dump</code> method:</p> <pre><code>collector.open()\ncollector.collect()\ncollector.close()\ncollector.dump()\n</code></pre> <p>The session data will be dumped to a yaml file called \"scrapli_replay_collector_session.yaml\" (configurable with the  <code>collector_session_filename</code> argument) in your current directory. Once you have a session stored, you can run the  \"server\" to create a semi-interactive ssh server!</p> <p>Note -- unless you have real dns server(s) setup, and you can resolve things, you should disable domain-lookup --  if you don't the timeouts may (will!?) get exceeded and it will cause collection to fail in confusing ways.</p>"},{"location":"user_guide/basic_usage/#server","title":"Server","text":"<p>Starting the scrapli replay server is simple!</p> <pre><code>import asyncio\nfrom scrapli_replay.server.server import start\n\n\nasync def main() -&gt; None:\n    await start(port=2001, collect_data=\"scrapli_replay_collector_session.yaml\")\n\n\nif __name__ == \"__main__\":\n    loop = asyncio.get_event_loop()\n    loop.run_until_complete(main())\n    loop.run_forever()\n</code></pre> <p>You can pass whatever port you wish for the <code>port</code> argument, and the <code>collect_data</code> must be the collected  data from the collector.</p> <p>Once the server is running you should be able to SSH to the server on the provided port just as if it were a \"real\"  device! The username and password will always be \"scrapli\" regardless of what the credentials were for the collected  server -- this is done so we never have to deal with or think about storing credentials.</p> <p>There are several big caveats to be aware of!</p> <ul> <li>Credentials: username/password (including for \"enable\" password) will always be \"scrapli\", as mentioned this is to    keep things simple and not deal with storing any credential data</li> <li>Configs: configuration things are not supported and probably won't ever be. It would be a lot of work to keep    track of when/if a user sends a config and what the resulting configuration would look like.</li> </ul> <p>The remaining major caveats are all around the \"paging\" behavior of the mock server(s). Before diving into these  caveats, it is worth knowing a little bit about how scrapli behaves in general. Typical scrapli connections are  opened, and an \"on_open\" function is executed -- this function normally disables pagination on a device, this is done so  scrapli never has to deal with prompts like \"--More--\" during the output of a command. The collector/server stores  the commands that are executed in the \"on_open\" function, and assumes that these commands disable pagination for  the given device (this is true for all core platforms, so it must be true, right? :)). With that out of the way:</p> <ul> <li>Disabling pagination requires all \"on_open\" commands to be executed: if the \"on_open\" command for your platform    contains \"terminal length 0\" and \"terminal width 512\", both commands must be seen before the server will disable    pagination. If you send just \"terminal length 0\" (even though this disables pagination on IOSXE/etc.) but have    not also sent \"terminal width 512\" the server will show you paginated output!</li> <li>Re-enabling pagination/logging in/out: You cannot re-enable pagination on the server, the only way to do this is    to exit/re-connect. This is because the collector has no way to know what commands are actually doing/what    commands disable/re-enable pagination (and we would never re-enable pagination in scrapli anyway!).</li> </ul> <p>With all the caveats out of the way, let's check out a mock server:</p> <pre><code>$ ssh localhost -p 2001 -l scrapli\nWarning: Permanently added '[localhost]:2222' (RSA) to the list of known hosts.\nPassword:\nC3560CX#show version\nCisco IOS Software, C3560CX Software (C3560CX-UNIVERSALK9-M), Version 15.2(4)E7, RELEASE SOFTWARE (fc2)\nTechnical Support: http://www.cisco.com/techsupport\nCopyright (c) 1986-2018 by Cisco Systems, Inc.\nCompiled Tue 18-Sep-18 13:20 by prod_rel_team\n\nROM: Bootstrap program is C3560CX boot loader\nBOOTLDR: C3560CX Boot Loader (C3560CX-HBOOT-M) Version 15.2(4r)E5, RELEASE SOFTWARE (fc4)\n\nC3560CX uptime is 1 week, 3 days, 2 hours, 55 minutes\nSystem returned to ROM by power-on\nSystem restarted at 07:13:48 PST Thu Jan 14 2021\nSystem image file is \"flash:c3560cx-universalk9-mz.152-4.E7.bin\"\nLast reload reason: power-on\n\n\n\nThis product contains cryptographic features and is subject to United\nStates and local country laws governing import, export, transfer and\nuse. Delivery of Cisco cryptographic products does not imply\nthird-party authority to import, export, distribute or use encryption.\nImporters, exporters, distributors and users are responsible for\n --More--\nC3560CX#\n</code></pre> <p>In the above output we connect to the mock server (with username/password of \"scrapli\") and execute the \"show  version\" command -- as paging has not been disabled we get the lovely \"--More--\" pagination indicator. Simply  sending another return here gets us back to our prompt.</p> <p>Continuing on... let's try to disable paging:</p> <pre><code>&lt;&lt; SNIP &gt;&gt;\nThis product contains cryptographic features and is subject to United\nStates and local country laws governing import, export, transfer and\nuse. Delivery of Cisco cryptographic products does not imply\nthird-party authority to import, export, distribute or use encryption.\nImporters, exporters, distributors and users are responsible for\n --More--\nC3560CX#terminal length 0\nC3560CX#terminal width 511\n% Unknown command or computer name, or unable to find computer address\nC3560CX#terminal width 512\nC3560CX#\n</code></pre> <p>Whoops - you can see that sending \"terminal width 511\" (instead of the \"correct\" command from the \"on_open\"  function \"terminal width 512\") caused the server to send us an \"Unknown command\" output -- similar to if you sent an  bad command on a \"real\" switch.</p> <p>Now that we have paging disabled, we can try the \"show version\" command again:</p> <pre><code>&lt;&lt; SNIP &gt;&gt;\nThis product contains cryptographic features and is subject to United\nStates and local country laws governing import, export, transfer and\nuse. Delivery of Cisco cryptographic products does not imply\nthird-party authority to import, export, distribute or use encryption.\nImporters, exporters, distributors and users are responsible for\n --More--\nC3560CX#terminal length 0\nC3560CX#terminal width 511\n% Unknown command or computer name, or unable to find computer address\nC3560CX#terminal width 512\nC3560CX#show version\nCisco IOS Software, C3560CX Software (C3560CX-UNIVERSALK9-M), Version 15.2(4)E7, RELEASE SOFTWARE (fc2)\nTechnical Support: http://www.cisco.com/techsupport\nCopyright (c) 1986-2018 by Cisco Systems, Inc.\nCompiled Tue 18-Sep-18 13:20 by prod_rel_team\n\nROM: Bootstrap program is C3560CX boot loader\nBOOTLDR: C3560CX Boot Loader (C3560CX-HBOOT-M) Version 15.2(4r)E5, RELEASE SOFTWARE (fc4)\n\nC3560CX uptime is 1 week, 3 days, 2 hours, 55 minutes\nSystem returned to ROM by power-on\nSystem restarted at 07:13:48 PST Thu Jan 14 2021\nSystem image file is \"flash:c3560cx-universalk9-mz.152-4.E7.bin\"\nLast reload reason: power-on\n\n\n\nThis product contains cryptographic features and is subject to United\nStates and local country laws governing import, export, transfer and\nuse. Delivery of Cisco cryptographic products does not imply\nthird-party authority to import, export, distribute or use encryption.\nImporters, exporters, distributors and users are responsible for\ncompliance with U.S. and local country laws. By using this product you\nagree to comply with applicable laws and regulations. If you are unable\nto comply with U.S. and local laws, return this product immediately.\n\nA summary of U.S. laws governing Cisco cryptographic products may be found at:\nhttp://www.cisco.com/wwl/export/crypto/tool/stqrg.html\n\nIf you require further assistance please contact us by sending email to\nexport@cisco.com.\n\nLicense Level: ipservices\nLicense Type: Permanent Right-To-Use\nNext reload license Level: ipservices\n\ncisco WS-C3560CX-8PC-S (APM86XXX) processor (revision A0) with 524288K bytes of memory.\nProcessor board ID FOC1911Y0NH\nLast reset from power-on\n3 Virtual Ethernet interfaces\n12 Gigabit Ethernet interfaces\nThe password-recovery mechanism is enabled.\n\n512K bytes of flash-simulated non-volatile configuration memory.\nBase ethernet MAC Address       : C8:00:84:B2:E9:80\nMotherboard assembly number     : 73-16471-04\nPower supply part number        : 341-0675-01\nMotherboard serial number       : FOC190608U7\nPower supply serial number      : DCB190430Z0\nModel revision number           : A0\nMotherboard revision number     : A0\nModel number                    : WS-C3560CX-8PC-S\nSystem serial number            : FOC1911Y0NH\nTop Assembly Part Number        : 68-5359-01\nTop Assembly Revision Number    : A0\nVersion ID                      : V01\nCLEI Code Number                : CMM1400DRA\nHardware Board Revision Number  : 0x02\n\n\nSwitch Ports Model                     SW Version            SW Image\n------ ----- -----                     ----------            ----------\n*    1 12    WS-C3560CX-8PC-S          15.2(4)E7             C3560CX-UNIVERSALK9-M\n\n\nConfiguration register is 0xF\n\nC3560CX#\n</code></pre> <p>That looks about right! How about config mode?</p> <pre><code>C3560CX#configure terminal\nEnter configuration commands, one per line.  End with CNTL/Z.\nC3560CX(config)#show version\n                  ^\n% Invalid input detected at '^' marker.\n\nC3560CX(config)#\n</code></pre> <p>Sending a \"show\" command in config mode fails like you'd expect too. This is because we \"collected\" all the  requested inputs at every privilege level. We can't send configs really because we didn't collect any and  collector/server is not built to deal with configs anyway.</p> <p>Ok, back down to exec?</p> <pre><code>C3560CX(config)#show version\n                  ^\n% Invalid input detected at '^' marker.\n\nC3560CX(config)#end\nC3560CX#disable\nC3560CX&gt;enable\nPassword:\nC3560CX#\n</code></pre> <p>Down to exec no problem, and back up to privilege exec -- remember that the password is \"scrapli\"!</p> <p>Thats about it for scrapli replay server -- the hope is that this can be useful for folks to do a bit of offline  testing of basic scrapli (or whatever else really) scripts!</p>"},{"location":"user_guide/installation/","title":"Installation","text":""},{"location":"user_guide/installation/#standard-installation","title":"Standard Installation","text":"<p>As outlined in the quick start, you should be able to pip install scrapli replay \"normally\":</p> <pre><code>pip install scrapli-replay\n</code></pre>"},{"location":"user_guide/installation/#installing-current-master-branch","title":"Installing current master branch","text":"<p>To install from the source repositories master branch:</p> <pre><code>pip install git+https://github.com/scrapli/scrapli_replay\n</code></pre>"},{"location":"user_guide/installation/#installing-current-develop-branch","title":"Installing current develop branch","text":"<p>To install from this repositories develop branch:</p> <pre><code>pip install -e git+https://github.com/scrapli/scrapli_replay.git@develop#egg=scrapli_replay\n</code></pre>"},{"location":"user_guide/installation/#installation-from-source","title":"Installation from Source","text":"<p>To install from source:</p> <pre><code>git clone https://github.com/scrapli/scrapli_replay\ncd scrapli_replay\npython setup.py install\n</code></pre>"},{"location":"user_guide/project_details/","title":"Project Details","text":""},{"location":"user_guide/project_details/#what-is-scrapli-replay","title":"What is scrapli replay","text":"<p>scrapli replay is a set of tools to help you test scrapli programs more easily. scrapli replay is very heavily  influenced by the <code>VCR.py</code> library, and the associated pytest plugin  pytest_vcr. scrapli replay's primary function is to provide a similar  testing experience for Telnet/SSH/NETCONF programs as these great tools do for HTTP/HTTPs programs.</p> <p>scrapli replay also contains tooling to help you \"dynamically\" build \"interactive\" SSH servers based on real life  SSH devices -- again, the purpose of this is to help you more easily test things offline, in CI environments, or  just have something safe to mess around with. There are quotes around \"dynamically\" and \"interactive\" as these are  perhaps loaded terms! \"dynamically\" meaning the scrapli replay \"collector\" can connect to, and collect output from a  real life SSH server. The scrapli replay \"server\" is then able to load the collected data and operate as a mock SSH  server -- any commands that you collected are able to be \"played back\" in an \"interactive\" fashion. Check out the  basic usage guide for more info -- and some examples -- to make things more clear! </p>"},{"location":"user_guide/project_details/#related-scrapli-libraries","title":"Related Scrapli Libraries","text":"<p>scrapli replay is really just test tooling built around the scrapli family of libraries -- and as such is not really  directly useful for connecting to devices and getting things done. If you are interested in getting things done,  check out the related scrapli libraries below:</p> <ul> <li>scrapli</li> <li>scrapli_netconf</li> <li>scrapli_community</li> <li>scrapli_cfg</li> <li>nornir_scrapli</li> </ul>"},{"location":"user_guide/quickstart/","title":"Quick Start Guide","text":""},{"location":"user_guide/quickstart/#installation","title":"Installation","text":"<p>In most cases installation via pip is the simplest and best way to install scrapli replay. See here for advanced installation details.</p> <pre><code>pip install scrapli-replay\n</code></pre>"},{"location":"user_guide/quickstart/#a-simple-example-pytest","title":"A Simple Example (Pytest)","text":"<p>Simply mark your tests containing scrapli code with the <code>scrapli_replay</code> marker:</p> <pre><code>@pytest.mark.scrapli_replay\ndef test_something_else():\n    with IOSXEDriver(**MY_DEVICE) as conn:\n        result = conn.send_command(\"show run | i hostname\")\n</code></pre>"},{"location":"user_guide/versioning/","title":"Versioning","text":"<p>Please see the scrapli \"core\" here documentation for versioning information.</p>"}]}